{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(models, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(models, handle)\n",
    "        \n",
    "def load_model(filename):\n",
    "    with open(filename, 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "    return model    \n",
    "        \n",
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y\n",
    "\n",
    "def lgb_trainer(X, y, params, n_folds):\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    models = []\n",
    "    for train_idx, test_idx in tqdm(skf.split(X.values, y.values)):\n",
    "            gc.collect()\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_tr, y_tr = augment(X_train.values, y_train.values)\n",
    "            X_tr = pd.DataFrame(X_tr)\n",
    "            trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "            test_data = lgb.Dataset(X.values[test_idx], label=y.values[test_idx])\n",
    "            model_lgb     = lgb.train(params, trn_data, 1000000, valid_sets = [trn_data, test_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "            models.append(model_lgb)\n",
    "            auc = roc_auc_score(y.values[test_idx], model_lgb.predict(X.values[test_idx]))\n",
    "    return models\n",
    "\n",
    "def lgb_trainer_no_aug(X, y, params, n_folds):\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    models = []\n",
    "    for train_idx, test_idx in tqdm(skf.split(X.values, y.values)):\n",
    "            gc.collect()\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_tr, y_tr = X_train.values, y_train.values\n",
    "            X_tr = pd.DataFrame(X_tr)\n",
    "            trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "            test_data = lgb.Dataset(X.values[test_idx], label=y.values[test_idx])\n",
    "            model_lgb     = lgb.train(params, trn_data, 1000000, valid_sets = [trn_data, test_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "            models.append(model_lgb)\n",
    "            auc = roc_auc_score(y.values[test_idx], model_lgb.predict(X.values[test_idx]))\n",
    "    return models\n",
    "\n",
    "def lgb_trainer_for_bayesian_optim(X, y, params):\n",
    "        X_tr, X_val, y_tr, y_val  = train_test_split(X, y, test_size = 0.2, random_state=42)    \n",
    "        trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "        test_data = lgb.Dataset(X_val, label=y_val)\n",
    "        model_lgb     = lgb.train(params, trn_data, 1000000, valid_sets = [trn_data, test_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "        auc = roc_auc_score(y_val, model_lgb.predict(X_val))\n",
    "        return auc\n",
    "\n",
    "def test_f(X, y, models):\n",
    "    preds = pd.DataFrame({})\n",
    "    for i, model in enumerate(models):\n",
    "        preds[str(i)] = model.predict(X)\n",
    "        print(f\"Fold: {i} \\t Score: {roc_auc_score(y, preds[str(i)].values)}\")\n",
    "    averaged_preds = preds.mean(axis=1)\n",
    "    scorre = roc_auc_score(y, averaged_preds)\n",
    "    print(f\"Score: {scorre}\")\n",
    "    return scorre, averaged_preds, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please workkkkk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "TRAIN = 'data/train.csv'\n",
    "# TEST = 'data/test.csv'\n",
    "TEST = 'data/da_real_test.csv'\n",
    "SAMPLE = 'data/sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN)\n",
    "test = pd.read_csv(TEST)\n",
    "whole = train.append(test)\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Partition real test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9322038c88144539b25a23f524c25dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(TEST)\n",
    "df_test.drop(['ID_code'], axis=1, inplace=True)\n",
    "df_test = df_test.values\n",
    "\n",
    "unique_samples = []\n",
    "unique_count = np.zeros_like(df_test)\n",
    "for feature in tqdm(range(df_test.shape[1])):\n",
    "    _, index_, count_ = np.unique(df_test[:, feature], return_counts=True, return_index=True)\n",
    "    unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "# Samples which have unique values are real the others are fake\n",
    "real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "print(len(real_samples_indexes))\n",
    "print(len(synthetic_samples_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9c19e5c63e44b8b4a61d7be19a56ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_real = df_test[real_samples_indexes].copy()\n",
    "\n",
    "generator_for_each_synthetic_sample = []\n",
    "# Using 20,000 samples should be enough. \n",
    "# You can use all of the 100,000 and get the same results (but 5 times slower)\n",
    "for cur_sample_index in tqdm(synthetic_samples_indexes[:20000]):\n",
    "    cur_synthetic_sample = df_test[cur_sample_index]\n",
    "    potential_generators = df_test_real == cur_synthetic_sample\n",
    "\n",
    "    # A verified generator for a synthetic sample is achieved\n",
    "    # only if the value of a feature appears only once in the\n",
    "    # entire real samples set\n",
    "    features_mask = np.sum(potential_generators, axis=0) == 1\n",
    "    verified_generators_mask = np.any(potential_generators[:, features_mask], axis=1)\n",
    "    verified_generators_for_sample = real_samples_indexes[np.argwhere(verified_generators_mask)[:, 0]]\n",
    "    generator_for_each_synthetic_sample.append(set(verified_generators_for_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cbbe7cfa0d4b65b4bd277a2e7a3f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0b0338ba1044e1b7dcb0b78373e81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "50000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "public_LB = generator_for_each_synthetic_sample[0]\n",
    "for x in tqdm(generator_for_each_synthetic_sample):\n",
    "    if public_LB.intersection(x):\n",
    "        public_LB = public_LB.union(x)\n",
    "\n",
    "private_LB = generator_for_each_synthetic_sample[1]\n",
    "for x in tqdm(generator_for_each_synthetic_sample):\n",
    "    if private_LB.intersection(x):\n",
    "        private_LB = private_LB.union(x)\n",
    "        \n",
    "print(len(public_LB))\n",
    "print(len(private_LB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_test.iloc[list(public_LB) + list(private_LB)].to_csv('data/da_real_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kekekek = pd.read_csv('data/da_real_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "train_uniques = train.nunique()\n",
    "test_uniques = test.nunique()\n",
    "whole_uniques = whole.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff6ac9ad8d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,8))\n",
    "plt.scatter(train.columns, train_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff693710128>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,8))\n",
    "plt.scatter(test.columns, test_uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff693521cc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(30,8))\n",
    "plt.scatter(whole.columns, whole_uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Augment unique count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def augment_uniques(data):\n",
    "    maps = {}\n",
    "    for feature in tqdm(data.columns):\n",
    "        if feature in ['ID_code', 'target']:\n",
    "            continue\n",
    "        a, b = np.unique(data[feature], return_counts=True)\n",
    "        unique_map = dict(zip(a, b))\n",
    "        maps[feature] = unique_map\n",
    "        data[f'count_{feature}'] = data[feature].map(unique_map)\n",
    "    return data, maps  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def answer_agument(testdf, maps):\n",
    "    for feature in tqdm(testdf.columns):\n",
    "        if feature in ['ID_code']:\n",
    "            continue\n",
    "        testdf[f'count_{feature}'] = testdf[feature].map(maps[feature])    \n",
    "    return testdf    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423316350eb54d389229bb979c51513c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "whole, unique_map = augment_uniques(whole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 402)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "traindf, testdf = whole[:200000], whole[200000:]\n",
    "y = traindf.target\n",
    "X = traindf.drop(['target', 'ID_code'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Xtr, Xval, ytr, yval  = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.001,\n",
    "    'max_depth': 4,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 100,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 10,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': -1,\n",
    "    'seed':42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.903531\tvalid_1's auc: 0.874673\n",
      "[10000]\ttraining's auc: 0.911923\tvalid_1's auc: 0.880603\n",
      "[15000]\ttraining's auc: 0.918925\tvalid_1's auc: 0.885082\n",
      "[20000]\ttraining's auc: 0.924452\tvalid_1's auc: 0.888236\n",
      "[25000]\ttraining's auc: 0.929235\tvalid_1's auc: 0.890761\n",
      "[30000]\ttraining's auc: 0.933417\tvalid_1's auc: 0.892645\n",
      "[35000]\ttraining's auc: 0.937157\tvalid_1's auc: 0.894111\n",
      "[40000]\ttraining's auc: 0.940436\tvalid_1's auc: 0.895054\n",
      "[45000]\ttraining's auc: 0.943518\tvalid_1's auc: 0.895902\n",
      "[50000]\ttraining's auc: 0.946378\tvalid_1's auc: 0.896558\n",
      "[55000]\ttraining's auc: 0.94904\tvalid_1's auc: 0.89703\n",
      "[60000]\ttraining's auc: 0.951526\tvalid_1's auc: 0.897374\n",
      "[65000]\ttraining's auc: 0.95383\tvalid_1's auc: 0.897618\n",
      "[70000]\ttraining's auc: 0.956053\tvalid_1's auc: 0.897785\n",
      "[75000]\ttraining's auc: 0.958153\tvalid_1's auc: 0.897918\n",
      "[80000]\ttraining's auc: 0.960189\tvalid_1's auc: 0.898014\n",
      "[85000]\ttraining's auc: 0.962113\tvalid_1's auc: 0.898062\n",
      "[90000]\ttraining's auc: 0.963918\tvalid_1's auc: 0.898037\n",
      "Early stopping, best iteration is:\n",
      "[86332]\ttraining's auc: 0.962597\tvalid_1's auc: 0.898071\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.901634\tvalid_1's auc: 0.875386\n",
      "[10000]\ttraining's auc: 0.909727\tvalid_1's auc: 0.882054\n",
      "[15000]\ttraining's auc: 0.916719\tvalid_1's auc: 0.88707\n",
      "[20000]\ttraining's auc: 0.922409\tvalid_1's auc: 0.890463\n",
      "[25000]\ttraining's auc: 0.92734\tvalid_1's auc: 0.892989\n",
      "[30000]\ttraining's auc: 0.931584\tvalid_1's auc: 0.894828\n",
      "[35000]\ttraining's auc: 0.935381\tvalid_1's auc: 0.896315\n",
      "[40000]\ttraining's auc: 0.938707\tvalid_1's auc: 0.897337\n",
      "[45000]\ttraining's auc: 0.941806\tvalid_1's auc: 0.898153\n",
      "[50000]\ttraining's auc: 0.944691\tvalid_1's auc: 0.898759\n",
      "[55000]\ttraining's auc: 0.94734\tvalid_1's auc: 0.8992\n",
      "[60000]\ttraining's auc: 0.949877\tvalid_1's auc: 0.899548\n",
      "[65000]\ttraining's auc: 0.952229\tvalid_1's auc: 0.899703\n",
      "[70000]\ttraining's auc: 0.95448\tvalid_1's auc: 0.899874\n",
      "[75000]\ttraining's auc: 0.956599\tvalid_1's auc: 0.899971\n",
      "[80000]\ttraining's auc: 0.958635\tvalid_1's auc: 0.900018\n",
      "Early stopping, best iteration is:\n",
      "[79851]\ttraining's auc: 0.958575\tvalid_1's auc: 0.900025\n"
     ]
    }
   ],
   "source": [
    "rank_models = lgb_trainer_no_aug(Xtr, ytr, param, n_folds = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 \t Score: 0.8988752618374661\n",
      "Fold: 1 \t Score: 0.8989653875172066\n",
      "Score: 0.9014838553784754\n"
     ]
    }
   ],
   "source": [
    "scorre, q, w = test_f(Xval, yval, rank_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on new bayesian params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.8620098138074975,\n",
       " 'params': {'bagging_fraction': 0.8,\n",
       "  'feature_fraction': 0.039575020369471824,\n",
       "  'learning_rate': 0.007665078680394379,\n",
       "  'min_data_in_leaf': 98.92002156410791,\n",
       "  'min_sum_hessian_in_leaf': 14.910533683368534,\n",
       "  'num_leaves': 37.894176676473215,\n",
       "  'num_threads': 6.37590307317559,\n",
       "  'reg_alpha': 0.6718099633747782,\n",
       "  'reg_lambda': 0.07763407837596625}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {\n",
    "#     'bagging_fraction': 0.7244760011046869,\n",
    "#   'feature_fraction': 0.03797197526119348,\n",
    "#   'learning_rate': 0.006727693701374024,\n",
    "#   'min_data_in_leaf': 104,\n",
    "#   'min_sum_hessian_in_leaf': 10,\n",
    "#   'num_leaves': 10,\n",
    "#   'num_threads': 7,\n",
    "#   'reg_alpha': 0.41038292303562973,\n",
    "#   'reg_lambda': 0.7555511385430487,\n",
    "#     'boost': 'gbdt',\n",
    "#     'metric':'auc',\n",
    "#     'tree_learner': 'serial',\n",
    "#     'objective': 'binary', \n",
    "#     'verbosity': -1,\n",
    "#     'seed':42,\n",
    "# }\n",
    "\n",
    "#^best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'bagging_fraction': 0.7244760011046869,\n",
    "  'feature_fraction': 0.03797197526119348,\n",
    "  'learning_rate': 0.006727693701374024,\n",
    "  'min_data_in_leaf': 104,\n",
    "  'min_sum_hessian_in_leaf': 10,\n",
    "  'num_leaves': 37,\n",
    "  'num_threads': 7,\n",
    "  'reg_alpha': 0.41038292303562973,\n",
    "  'reg_lambda': 0.7555511385430487,\n",
    "    'boost': 'gbdt',\n",
    "    'metric':'auc',\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': -1,\n",
    "    'seed':42,\n",
    "}\n",
    "\n",
    "#^best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>var_106</th>\n",
       "      <th>...</th>\n",
       "      <th>count_var_90</th>\n",
       "      <th>count_var_91</th>\n",
       "      <th>count_var_92</th>\n",
       "      <th>count_var_93</th>\n",
       "      <th>count_var_94</th>\n",
       "      <th>count_var_95</th>\n",
       "      <th>count_var_96</th>\n",
       "      <th>count_var_97</th>\n",
       "      <th>count_var_98</th>\n",
       "      <th>count_var_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153248</th>\n",
       "      <td>12.3039</td>\n",
       "      <td>-8.3899</td>\n",
       "      <td>-9.1195</td>\n",
       "      <td>-12.8622</td>\n",
       "      <td>13.0944</td>\n",
       "      <td>29.7810</td>\n",
       "      <td>1.5517</td>\n",
       "      <td>12.5723</td>\n",
       "      <td>4.9254</td>\n",
       "      <td>13.1096</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67802</th>\n",
       "      <td>15.4069</td>\n",
       "      <td>2.7820</td>\n",
       "      <td>-6.0590</td>\n",
       "      <td>-13.6862</td>\n",
       "      <td>10.6586</td>\n",
       "      <td>33.0855</td>\n",
       "      <td>1.5357</td>\n",
       "      <td>8.0175</td>\n",
       "      <td>4.4437</td>\n",
       "      <td>6.8451</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148889</th>\n",
       "      <td>9.6427</td>\n",
       "      <td>-4.6261</td>\n",
       "      <td>-4.8543</td>\n",
       "      <td>-6.3076</td>\n",
       "      <td>11.8062</td>\n",
       "      <td>26.9634</td>\n",
       "      <td>1.5886</td>\n",
       "      <td>12.6750</td>\n",
       "      <td>2.8893</td>\n",
       "      <td>8.7265</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103093</th>\n",
       "      <td>9.6881</td>\n",
       "      <td>-5.6696</td>\n",
       "      <td>-2.8435</td>\n",
       "      <td>7.1075</td>\n",
       "      <td>9.3962</td>\n",
       "      <td>9.1705</td>\n",
       "      <td>1.5112</td>\n",
       "      <td>12.4132</td>\n",
       "      <td>3.4052</td>\n",
       "      <td>10.0054</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104681</th>\n",
       "      <td>7.1128</td>\n",
       "      <td>-2.0830</td>\n",
       "      <td>4.6706</td>\n",
       "      <td>-7.6224</td>\n",
       "      <td>14.4174</td>\n",
       "      <td>21.1651</td>\n",
       "      <td>1.5490</td>\n",
       "      <td>15.1391</td>\n",
       "      <td>4.4376</td>\n",
       "      <td>7.7387</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80115</th>\n",
       "      <td>10.6817</td>\n",
       "      <td>-1.3115</td>\n",
       "      <td>3.0307</td>\n",
       "      <td>-16.8145</td>\n",
       "      <td>9.5617</td>\n",
       "      <td>24.0215</td>\n",
       "      <td>1.8553</td>\n",
       "      <td>10.2531</td>\n",
       "      <td>3.1575</td>\n",
       "      <td>8.5914</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38121</th>\n",
       "      <td>9.5732</td>\n",
       "      <td>-2.2330</td>\n",
       "      <td>2.5117</td>\n",
       "      <td>4.5858</td>\n",
       "      <td>18.2752</td>\n",
       "      <td>12.2863</td>\n",
       "      <td>1.7241</td>\n",
       "      <td>13.4893</td>\n",
       "      <td>3.9988</td>\n",
       "      <td>7.5953</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121094</th>\n",
       "      <td>17.1698</td>\n",
       "      <td>-3.0841</td>\n",
       "      <td>0.2938</td>\n",
       "      <td>-7.1315</td>\n",
       "      <td>8.2758</td>\n",
       "      <td>36.9356</td>\n",
       "      <td>1.4018</td>\n",
       "      <td>10.7558</td>\n",
       "      <td>3.0204</td>\n",
       "      <td>8.2641</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182119</th>\n",
       "      <td>7.7740</td>\n",
       "      <td>-3.8156</td>\n",
       "      <td>-1.8384</td>\n",
       "      <td>-15.8406</td>\n",
       "      <td>22.5392</td>\n",
       "      <td>26.6656</td>\n",
       "      <td>1.8102</td>\n",
       "      <td>7.7520</td>\n",
       "      <td>3.5377</td>\n",
       "      <td>8.1789</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48981</th>\n",
       "      <td>11.0465</td>\n",
       "      <td>5.0801</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>-8.7147</td>\n",
       "      <td>14.9587</td>\n",
       "      <td>21.1261</td>\n",
       "      <td>1.7395</td>\n",
       "      <td>10.4570</td>\n",
       "      <td>4.4646</td>\n",
       "      <td>10.7835</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84264</th>\n",
       "      <td>5.7186</td>\n",
       "      <td>-3.4517</td>\n",
       "      <td>-2.6655</td>\n",
       "      <td>-8.3266</td>\n",
       "      <td>18.1256</td>\n",
       "      <td>30.1082</td>\n",
       "      <td>1.6907</td>\n",
       "      <td>11.4534</td>\n",
       "      <td>4.1220</td>\n",
       "      <td>10.1944</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15044</th>\n",
       "      <td>13.9591</td>\n",
       "      <td>-3.9509</td>\n",
       "      <td>-6.1723</td>\n",
       "      <td>-4.3382</td>\n",
       "      <td>14.1737</td>\n",
       "      <td>21.6544</td>\n",
       "      <td>1.2326</td>\n",
       "      <td>14.7538</td>\n",
       "      <td>4.3556</td>\n",
       "      <td>6.6317</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11425</th>\n",
       "      <td>9.5574</td>\n",
       "      <td>-7.0090</td>\n",
       "      <td>1.7522</td>\n",
       "      <td>11.1032</td>\n",
       "      <td>18.7134</td>\n",
       "      <td>26.7300</td>\n",
       "      <td>1.7007</td>\n",
       "      <td>12.6699</td>\n",
       "      <td>4.2216</td>\n",
       "      <td>8.3073</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161109</th>\n",
       "      <td>6.0283</td>\n",
       "      <td>-3.4143</td>\n",
       "      <td>9.1569</td>\n",
       "      <td>-2.3919</td>\n",
       "      <td>14.3436</td>\n",
       "      <td>15.0514</td>\n",
       "      <td>1.6630</td>\n",
       "      <td>9.3706</td>\n",
       "      <td>5.3309</td>\n",
       "      <td>10.2524</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74171</th>\n",
       "      <td>5.0093</td>\n",
       "      <td>-1.9786</td>\n",
       "      <td>5.3243</td>\n",
       "      <td>-27.2838</td>\n",
       "      <td>15.4258</td>\n",
       "      <td>13.5943</td>\n",
       "      <td>1.5087</td>\n",
       "      <td>15.0068</td>\n",
       "      <td>4.0187</td>\n",
       "      <td>8.5123</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67739</th>\n",
       "      <td>10.0047</td>\n",
       "      <td>-1.6887</td>\n",
       "      <td>1.6622</td>\n",
       "      <td>-21.7360</td>\n",
       "      <td>18.5863</td>\n",
       "      <td>27.4228</td>\n",
       "      <td>1.6397</td>\n",
       "      <td>13.0915</td>\n",
       "      <td>3.5373</td>\n",
       "      <td>9.0176</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80755</th>\n",
       "      <td>7.1139</td>\n",
       "      <td>5.3229</td>\n",
       "      <td>-3.2626</td>\n",
       "      <td>4.6535</td>\n",
       "      <td>8.2120</td>\n",
       "      <td>18.6823</td>\n",
       "      <td>1.4675</td>\n",
       "      <td>14.2858</td>\n",
       "      <td>3.6242</td>\n",
       "      <td>7.4505</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138008</th>\n",
       "      <td>9.0556</td>\n",
       "      <td>3.7587</td>\n",
       "      <td>-1.4698</td>\n",
       "      <td>-16.7524</td>\n",
       "      <td>7.3127</td>\n",
       "      <td>18.9505</td>\n",
       "      <td>1.8267</td>\n",
       "      <td>11.4775</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>9.2716</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17267</th>\n",
       "      <td>14.6356</td>\n",
       "      <td>-2.2559</td>\n",
       "      <td>-6.6664</td>\n",
       "      <td>2.0764</td>\n",
       "      <td>15.4647</td>\n",
       "      <td>22.9027</td>\n",
       "      <td>1.6993</td>\n",
       "      <td>9.0143</td>\n",
       "      <td>3.3875</td>\n",
       "      <td>9.4389</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72712</th>\n",
       "      <td>13.2324</td>\n",
       "      <td>-4.4364</td>\n",
       "      <td>1.3949</td>\n",
       "      <td>2.1137</td>\n",
       "      <td>12.4826</td>\n",
       "      <td>28.0649</td>\n",
       "      <td>1.5737</td>\n",
       "      <td>14.7440</td>\n",
       "      <td>4.7375</td>\n",
       "      <td>11.4684</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26976</th>\n",
       "      <td>18.7217</td>\n",
       "      <td>-0.1070</td>\n",
       "      <td>-6.1744</td>\n",
       "      <td>-20.3188</td>\n",
       "      <td>22.8305</td>\n",
       "      <td>29.3490</td>\n",
       "      <td>1.3807</td>\n",
       "      <td>11.1756</td>\n",
       "      <td>5.0314</td>\n",
       "      <td>10.7592</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181576</th>\n",
       "      <td>6.1528</td>\n",
       "      <td>1.9325</td>\n",
       "      <td>7.2040</td>\n",
       "      <td>-11.9145</td>\n",
       "      <td>9.9606</td>\n",
       "      <td>20.2585</td>\n",
       "      <td>1.8423</td>\n",
       "      <td>12.2853</td>\n",
       "      <td>4.4438</td>\n",
       "      <td>8.6863</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194759</th>\n",
       "      <td>17.6000</td>\n",
       "      <td>-8.2079</td>\n",
       "      <td>10.2936</td>\n",
       "      <td>-2.0947</td>\n",
       "      <td>18.5341</td>\n",
       "      <td>15.7274</td>\n",
       "      <td>1.3395</td>\n",
       "      <td>11.4190</td>\n",
       "      <td>3.3775</td>\n",
       "      <td>4.7318</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>4.7816</td>\n",
       "      <td>5.3236</td>\n",
       "      <td>-4.9685</td>\n",
       "      <td>4.8837</td>\n",
       "      <td>12.8611</td>\n",
       "      <td>11.9225</td>\n",
       "      <td>1.3658</td>\n",
       "      <td>10.4628</td>\n",
       "      <td>5.8225</td>\n",
       "      <td>9.8007</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62392</th>\n",
       "      <td>6.7702</td>\n",
       "      <td>7.2426</td>\n",
       "      <td>-2.1867</td>\n",
       "      <td>3.0484</td>\n",
       "      <td>19.2613</td>\n",
       "      <td>26.4302</td>\n",
       "      <td>1.6436</td>\n",
       "      <td>7.4634</td>\n",
       "      <td>4.3392</td>\n",
       "      <td>10.6411</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179546</th>\n",
       "      <td>4.3715</td>\n",
       "      <td>-5.1588</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>-4.5267</td>\n",
       "      <td>20.0066</td>\n",
       "      <td>8.6382</td>\n",
       "      <td>1.8326</td>\n",
       "      <td>12.8438</td>\n",
       "      <td>3.5447</td>\n",
       "      <td>11.3310</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181416</th>\n",
       "      <td>8.1812</td>\n",
       "      <td>-8.8668</td>\n",
       "      <td>-7.1106</td>\n",
       "      <td>0.9843</td>\n",
       "      <td>21.0490</td>\n",
       "      <td>6.3684</td>\n",
       "      <td>1.7847</td>\n",
       "      <td>9.7158</td>\n",
       "      <td>4.2544</td>\n",
       "      <td>7.9608</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97890</th>\n",
       "      <td>8.8547</td>\n",
       "      <td>-5.1627</td>\n",
       "      <td>1.5885</td>\n",
       "      <td>-0.1872</td>\n",
       "      <td>12.4185</td>\n",
       "      <td>22.6860</td>\n",
       "      <td>1.3501</td>\n",
       "      <td>8.9576</td>\n",
       "      <td>4.1289</td>\n",
       "      <td>9.6520</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116273</th>\n",
       "      <td>12.4371</td>\n",
       "      <td>-2.7484</td>\n",
       "      <td>-0.7565</td>\n",
       "      <td>-1.9330</td>\n",
       "      <td>13.4358</td>\n",
       "      <td>31.7538</td>\n",
       "      <td>1.7001</td>\n",
       "      <td>10.9189</td>\n",
       "      <td>4.1129</td>\n",
       "      <td>7.2264</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22851</th>\n",
       "      <td>8.4377</td>\n",
       "      <td>-7.9098</td>\n",
       "      <td>8.5074</td>\n",
       "      <td>-4.8366</td>\n",
       "      <td>14.0847</td>\n",
       "      <td>35.2860</td>\n",
       "      <td>1.8981</td>\n",
       "      <td>13.9292</td>\n",
       "      <td>4.2378</td>\n",
       "      <td>9.3349</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156730</th>\n",
       "      <td>8.6902</td>\n",
       "      <td>-5.9632</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>-10.8708</td>\n",
       "      <td>18.3043</td>\n",
       "      <td>35.4737</td>\n",
       "      <td>1.7076</td>\n",
       "      <td>10.5016</td>\n",
       "      <td>5.0352</td>\n",
       "      <td>8.7784</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130608</th>\n",
       "      <td>12.4530</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>-5.2641</td>\n",
       "      <td>5.7570</td>\n",
       "      <td>4.5880</td>\n",
       "      <td>22.9027</td>\n",
       "      <td>1.8413</td>\n",
       "      <td>11.8975</td>\n",
       "      <td>4.1264</td>\n",
       "      <td>12.6660</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159765</th>\n",
       "      <td>8.0867</td>\n",
       "      <td>0.6868</td>\n",
       "      <td>-2.6643</td>\n",
       "      <td>-3.3190</td>\n",
       "      <td>9.1665</td>\n",
       "      <td>32.9874</td>\n",
       "      <td>1.6886</td>\n",
       "      <td>12.3572</td>\n",
       "      <td>4.8448</td>\n",
       "      <td>11.7098</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85305</th>\n",
       "      <td>13.0528</td>\n",
       "      <td>-5.7261</td>\n",
       "      <td>-7.6312</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>16.1028</td>\n",
       "      <td>19.6188</td>\n",
       "      <td>1.7986</td>\n",
       "      <td>12.8634</td>\n",
       "      <td>3.1102</td>\n",
       "      <td>9.3830</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184779</th>\n",
       "      <td>16.3305</td>\n",
       "      <td>2.0590</td>\n",
       "      <td>-6.7864</td>\n",
       "      <td>-11.1086</td>\n",
       "      <td>13.7436</td>\n",
       "      <td>34.7360</td>\n",
       "      <td>1.5489</td>\n",
       "      <td>13.4240</td>\n",
       "      <td>2.9977</td>\n",
       "      <td>10.6633</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103355</th>\n",
       "      <td>16.2478</td>\n",
       "      <td>-1.2022</td>\n",
       "      <td>2.3087</td>\n",
       "      <td>-12.0580</td>\n",
       "      <td>4.3293</td>\n",
       "      <td>34.3116</td>\n",
       "      <td>1.6451</td>\n",
       "      <td>14.5420</td>\n",
       "      <td>3.4931</td>\n",
       "      <td>4.9840</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>13.6765</td>\n",
       "      <td>-3.4317</td>\n",
       "      <td>-8.7375</td>\n",
       "      <td>-7.0389</td>\n",
       "      <td>10.4317</td>\n",
       "      <td>14.1209</td>\n",
       "      <td>1.6604</td>\n",
       "      <td>9.6230</td>\n",
       "      <td>6.1262</td>\n",
       "      <td>9.8388</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199041</th>\n",
       "      <td>6.8000</td>\n",
       "      <td>0.0966</td>\n",
       "      <td>4.6179</td>\n",
       "      <td>-4.3476</td>\n",
       "      <td>8.4892</td>\n",
       "      <td>16.1466</td>\n",
       "      <td>1.4766</td>\n",
       "      <td>11.5042</td>\n",
       "      <td>3.9157</td>\n",
       "      <td>9.1331</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64925</th>\n",
       "      <td>8.7056</td>\n",
       "      <td>-3.8304</td>\n",
       "      <td>2.6281</td>\n",
       "      <td>-13.5445</td>\n",
       "      <td>16.0298</td>\n",
       "      <td>19.6181</td>\n",
       "      <td>1.6427</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>4.2153</td>\n",
       "      <td>7.7219</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194027</th>\n",
       "      <td>11.7439</td>\n",
       "      <td>5.4209</td>\n",
       "      <td>-7.8645</td>\n",
       "      <td>-13.2253</td>\n",
       "      <td>12.8142</td>\n",
       "      <td>16.7491</td>\n",
       "      <td>1.6918</td>\n",
       "      <td>6.7586</td>\n",
       "      <td>4.0466</td>\n",
       "      <td>9.2830</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59735</th>\n",
       "      <td>12.2455</td>\n",
       "      <td>-5.8503</td>\n",
       "      <td>3.9072</td>\n",
       "      <td>0.4475</td>\n",
       "      <td>10.2110</td>\n",
       "      <td>33.3054</td>\n",
       "      <td>1.6742</td>\n",
       "      <td>12.4342</td>\n",
       "      <td>3.7860</td>\n",
       "      <td>6.6762</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>10.4436</td>\n",
       "      <td>-4.5353</td>\n",
       "      <td>-7.4180</td>\n",
       "      <td>-27.8329</td>\n",
       "      <td>12.1030</td>\n",
       "      <td>3.9614</td>\n",
       "      <td>1.6275</td>\n",
       "      <td>10.3704</td>\n",
       "      <td>4.1402</td>\n",
       "      <td>5.5864</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64820</th>\n",
       "      <td>8.5138</td>\n",
       "      <td>-7.2189</td>\n",
       "      <td>10.7274</td>\n",
       "      <td>-17.1291</td>\n",
       "      <td>11.4415</td>\n",
       "      <td>29.0261</td>\n",
       "      <td>1.6791</td>\n",
       "      <td>12.7206</td>\n",
       "      <td>5.4093</td>\n",
       "      <td>10.0675</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67221</th>\n",
       "      <td>8.8009</td>\n",
       "      <td>-4.3238</td>\n",
       "      <td>4.4994</td>\n",
       "      <td>-6.2105</td>\n",
       "      <td>14.5756</td>\n",
       "      <td>13.8840</td>\n",
       "      <td>1.3708</td>\n",
       "      <td>8.1381</td>\n",
       "      <td>3.2814</td>\n",
       "      <td>10.1917</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41090</th>\n",
       "      <td>13.9853</td>\n",
       "      <td>-6.9652</td>\n",
       "      <td>-1.5719</td>\n",
       "      <td>5.3660</td>\n",
       "      <td>10.6796</td>\n",
       "      <td>18.2589</td>\n",
       "      <td>1.4350</td>\n",
       "      <td>10.3381</td>\n",
       "      <td>5.0589</td>\n",
       "      <td>9.9539</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16023</th>\n",
       "      <td>13.3079</td>\n",
       "      <td>-5.7326</td>\n",
       "      <td>2.4564</td>\n",
       "      <td>-12.1381</td>\n",
       "      <td>14.6616</td>\n",
       "      <td>35.9303</td>\n",
       "      <td>1.8284</td>\n",
       "      <td>10.1283</td>\n",
       "      <td>3.2678</td>\n",
       "      <td>10.5745</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191335</th>\n",
       "      <td>7.7407</td>\n",
       "      <td>2.8590</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>-16.6416</td>\n",
       "      <td>11.2234</td>\n",
       "      <td>19.3332</td>\n",
       "      <td>1.5297</td>\n",
       "      <td>9.5088</td>\n",
       "      <td>3.5991</td>\n",
       "      <td>8.2905</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175203</th>\n",
       "      <td>9.7292</td>\n",
       "      <td>2.1664</td>\n",
       "      <td>5.3120</td>\n",
       "      <td>6.5626</td>\n",
       "      <td>3.3097</td>\n",
       "      <td>16.8707</td>\n",
       "      <td>1.5284</td>\n",
       "      <td>15.0397</td>\n",
       "      <td>4.0009</td>\n",
       "      <td>7.9658</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126324</th>\n",
       "      <td>18.6411</td>\n",
       "      <td>-1.2222</td>\n",
       "      <td>2.7005</td>\n",
       "      <td>-19.2063</td>\n",
       "      <td>20.5494</td>\n",
       "      <td>1.4681</td>\n",
       "      <td>1.4439</td>\n",
       "      <td>13.7784</td>\n",
       "      <td>4.5149</td>\n",
       "      <td>5.0712</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112727</th>\n",
       "      <td>7.1449</td>\n",
       "      <td>-5.1964</td>\n",
       "      <td>-1.8596</td>\n",
       "      <td>1.7157</td>\n",
       "      <td>12.3552</td>\n",
       "      <td>26.6894</td>\n",
       "      <td>1.5645</td>\n",
       "      <td>8.7321</td>\n",
       "      <td>5.3719</td>\n",
       "      <td>10.2320</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87498</th>\n",
       "      <td>13.8346</td>\n",
       "      <td>-5.2852</td>\n",
       "      <td>-3.9701</td>\n",
       "      <td>-23.3021</td>\n",
       "      <td>12.4462</td>\n",
       "      <td>18.5291</td>\n",
       "      <td>1.1919</td>\n",
       "      <td>12.8350</td>\n",
       "      <td>4.5260</td>\n",
       "      <td>7.7344</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168266</th>\n",
       "      <td>10.9118</td>\n",
       "      <td>1.3881</td>\n",
       "      <td>0.2133</td>\n",
       "      <td>5.6864</td>\n",
       "      <td>10.1040</td>\n",
       "      <td>19.2465</td>\n",
       "      <td>1.5859</td>\n",
       "      <td>9.6406</td>\n",
       "      <td>2.5343</td>\n",
       "      <td>7.9942</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137337</th>\n",
       "      <td>13.3511</td>\n",
       "      <td>-0.7888</td>\n",
       "      <td>1.1247</td>\n",
       "      <td>1.6132</td>\n",
       "      <td>6.5224</td>\n",
       "      <td>24.3580</td>\n",
       "      <td>1.3705</td>\n",
       "      <td>10.0145</td>\n",
       "      <td>3.4787</td>\n",
       "      <td>9.3370</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>8.4855</td>\n",
       "      <td>-3.3291</td>\n",
       "      <td>-8.2549</td>\n",
       "      <td>6.2647</td>\n",
       "      <td>22.4251</td>\n",
       "      <td>17.0955</td>\n",
       "      <td>1.6102</td>\n",
       "      <td>10.0473</td>\n",
       "      <td>3.6831</td>\n",
       "      <td>6.5588</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110268</th>\n",
       "      <td>8.0720</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>-3.3969</td>\n",
       "      <td>-21.7213</td>\n",
       "      <td>14.4257</td>\n",
       "      <td>25.4901</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>13.4207</td>\n",
       "      <td>5.0181</td>\n",
       "      <td>6.2502</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119879</th>\n",
       "      <td>11.4356</td>\n",
       "      <td>2.1235</td>\n",
       "      <td>2.4141</td>\n",
       "      <td>1.0572</td>\n",
       "      <td>12.3502</td>\n",
       "      <td>31.0560</td>\n",
       "      <td>1.2526</td>\n",
       "      <td>10.9511</td>\n",
       "      <td>3.5605</td>\n",
       "      <td>6.9004</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103694</th>\n",
       "      <td>9.0806</td>\n",
       "      <td>-0.4575</td>\n",
       "      <td>-0.7455</td>\n",
       "      <td>-3.1967</td>\n",
       "      <td>18.7250</td>\n",
       "      <td>29.9525</td>\n",
       "      <td>1.4331</td>\n",
       "      <td>11.9829</td>\n",
       "      <td>4.7741</td>\n",
       "      <td>9.3372</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131932</th>\n",
       "      <td>16.7760</td>\n",
       "      <td>1.0075</td>\n",
       "      <td>-3.9879</td>\n",
       "      <td>-11.9743</td>\n",
       "      <td>8.9245</td>\n",
       "      <td>24.8257</td>\n",
       "      <td>1.7044</td>\n",
       "      <td>11.3579</td>\n",
       "      <td>3.2504</td>\n",
       "      <td>6.9852</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146867</th>\n",
       "      <td>9.9775</td>\n",
       "      <td>7.4480</td>\n",
       "      <td>-9.2026</td>\n",
       "      <td>11.5793</td>\n",
       "      <td>10.5418</td>\n",
       "      <td>13.5978</td>\n",
       "      <td>1.7267</td>\n",
       "      <td>15.2246</td>\n",
       "      <td>3.1573</td>\n",
       "      <td>8.6953</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121958</th>\n",
       "      <td>11.6048</td>\n",
       "      <td>-3.4120</td>\n",
       "      <td>6.6996</td>\n",
       "      <td>-0.2966</td>\n",
       "      <td>23.0200</td>\n",
       "      <td>35.7618</td>\n",
       "      <td>1.5681</td>\n",
       "      <td>10.0765</td>\n",
       "      <td>4.7322</td>\n",
       "      <td>6.0260</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows  400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          var_0   var_1   var_10  var_100  var_101  var_102  var_103  var_104  \\\n",
       "153248  12.3039 -8.3899  -9.1195 -12.8622  13.0944  29.7810   1.5517  12.5723   \n",
       "67802   15.4069  2.7820  -6.0590 -13.6862  10.6586  33.0855   1.5357   8.0175   \n",
       "148889   9.6427 -4.6261  -4.8543  -6.3076  11.8062  26.9634   1.5886  12.6750   \n",
       "103093   9.6881 -5.6696  -2.8435   7.1075   9.3962   9.1705   1.5112  12.4132   \n",
       "104681   7.1128 -2.0830   4.6706  -7.6224  14.4174  21.1651   1.5490  15.1391   \n",
       "80115   10.6817 -1.3115   3.0307 -16.8145   9.5617  24.0215   1.8553  10.2531   \n",
       "38121    9.5732 -2.2330   2.5117   4.5858  18.2752  12.2863   1.7241  13.4893   \n",
       "121094  17.1698 -3.0841   0.2938  -7.1315   8.2758  36.9356   1.4018  10.7558   \n",
       "182119   7.7740 -3.8156  -1.8384 -15.8406  22.5392  26.6656   1.8102   7.7520   \n",
       "48981   11.0465  5.0801   0.6443  -8.7147  14.9587  21.1261   1.7395  10.4570   \n",
       "84264    5.7186 -3.4517  -2.6655  -8.3266  18.1256  30.1082   1.6907  11.4534   \n",
       "15044   13.9591 -3.9509  -6.1723  -4.3382  14.1737  21.6544   1.2326  14.7538   \n",
       "11425    9.5574 -7.0090   1.7522  11.1032  18.7134  26.7300   1.7007  12.6699   \n",
       "161109   6.0283 -3.4143   9.1569  -2.3919  14.3436  15.0514   1.6630   9.3706   \n",
       "74171    5.0093 -1.9786   5.3243 -27.2838  15.4258  13.5943   1.5087  15.0068   \n",
       "67739   10.0047 -1.6887   1.6622 -21.7360  18.5863  27.4228   1.6397  13.0915   \n",
       "80755    7.1139  5.3229  -3.2626   4.6535   8.2120  18.6823   1.4675  14.2858   \n",
       "138008   9.0556  3.7587  -1.4698 -16.7524   7.3127  18.9505   1.8267  11.4775   \n",
       "17267   14.6356 -2.2559  -6.6664   2.0764  15.4647  22.9027   1.6993   9.0143   \n",
       "72712   13.2324 -4.4364   1.3949   2.1137  12.4826  28.0649   1.5737  14.7440   \n",
       "26976   18.7217 -0.1070  -6.1744 -20.3188  22.8305  29.3490   1.3807  11.1756   \n",
       "181576   6.1528  1.9325   7.2040 -11.9145   9.9606  20.2585   1.8423  12.2853   \n",
       "194759  17.6000 -8.2079  10.2936  -2.0947  18.5341  15.7274   1.3395  11.4190   \n",
       "4252     4.7816  5.3236  -4.9685   4.8837  12.8611  11.9225   1.3658  10.4628   \n",
       "62392    6.7702  7.2426  -2.1867   3.0484  19.2613  26.4302   1.6436   7.4634   \n",
       "179546   4.3715 -5.1588   0.0495  -4.5267  20.0066   8.6382   1.8326  12.8438   \n",
       "181416   8.1812 -8.8668  -7.1106   0.9843  21.0490   6.3684   1.7847   9.7158   \n",
       "97890    8.8547 -5.1627   1.5885  -0.1872  12.4185  22.6860   1.3501   8.9576   \n",
       "116273  12.4371 -2.7484  -0.7565  -1.9330  13.4358  31.7538   1.7001  10.9189   \n",
       "22851    8.4377 -7.9098   8.5074  -4.8366  14.0847  35.2860   1.8981  13.9292   \n",
       "...         ...     ...      ...      ...      ...      ...      ...      ...   \n",
       "156730   8.6902 -5.9632   0.4416 -10.8708  18.3043  35.4737   1.7076  10.5016   \n",
       "130608  12.4530  0.3766  -5.2641   5.7570   4.5880  22.9027   1.8413  11.8975   \n",
       "159765   8.0867  0.6868  -2.6643  -3.3190   9.1665  32.9874   1.6886  12.3572   \n",
       "85305   13.0528 -5.7261  -7.6312   0.4544  16.1028  19.6188   1.7986  12.8634   \n",
       "184779  16.3305  2.0590  -6.7864 -11.1086  13.7436  34.7360   1.5489  13.4240   \n",
       "103355  16.2478 -1.2022   2.3087 -12.0580   4.3293  34.3116   1.6451  14.5420   \n",
       "5311    13.6765 -3.4317  -8.7375  -7.0389  10.4317  14.1209   1.6604   9.6230   \n",
       "199041   6.8000  0.0966   4.6179  -4.3476   8.4892  16.1466   1.4766  11.5042   \n",
       "64925    8.7056 -3.8304   2.6281 -13.5445  16.0298  19.6181   1.6427   7.4000   \n",
       "194027  11.7439  5.4209  -7.8645 -13.2253  12.8142  16.7491   1.6918   6.7586   \n",
       "59735   12.2455 -5.8503   3.9072   0.4475  10.2110  33.3054   1.6742  12.4342   \n",
       "769     10.4436 -4.5353  -7.4180 -27.8329  12.1030   3.9614   1.6275  10.3704   \n",
       "64820    8.5138 -7.2189  10.7274 -17.1291  11.4415  29.0261   1.6791  12.7206   \n",
       "67221    8.8009 -4.3238   4.4994  -6.2105  14.5756  13.8840   1.3708   8.1381   \n",
       "41090   13.9853 -6.9652  -1.5719   5.3660  10.6796  18.2589   1.4350  10.3381   \n",
       "16023   13.3079 -5.7326   2.4564 -12.1381  14.6616  35.9303   1.8284  10.1283   \n",
       "191335   7.7407  2.8590   0.4390 -16.6416  11.2234  19.3332   1.5297   9.5088   \n",
       "175203   9.7292  2.1664   5.3120   6.5626   3.3097  16.8707   1.5284  15.0397   \n",
       "126324  18.6411 -1.2222   2.7005 -19.2063  20.5494   1.4681   1.4439  13.7784   \n",
       "112727   7.1449 -5.1964  -1.8596   1.7157  12.3552  26.6894   1.5645   8.7321   \n",
       "87498   13.8346 -5.2852  -3.9701 -23.3021  12.4462  18.5291   1.1919  12.8350   \n",
       "168266  10.9118  1.3881   0.2133   5.6864  10.1040  19.2465   1.5859   9.6406   \n",
       "137337  13.3511 -0.7888   1.1247   1.6132   6.5224  24.3580   1.3705  10.0145   \n",
       "54886    8.4855 -3.3291  -8.2549   6.2647  22.4251  17.0955   1.6102  10.0473   \n",
       "110268   8.0720  0.0761  -3.3969 -21.7213  14.4257  25.4901   1.5233  13.4207   \n",
       "119879  11.4356  2.1235   2.4141   1.0572  12.3502  31.0560   1.2526  10.9511   \n",
       "103694   9.0806 -0.4575  -0.7455  -3.1967  18.7250  29.9525   1.4331  11.9829   \n",
       "131932  16.7760  1.0075  -3.9879 -11.9743   8.9245  24.8257   1.7044  11.3579   \n",
       "146867   9.9775  7.4480  -9.2026  11.5793  10.5418  13.5978   1.7267  15.2246   \n",
       "121958  11.6048 -3.4120   6.6996  -0.2966  23.0200  35.7618   1.5681  10.0765   \n",
       "\n",
       "        var_105  var_106      ...       count_var_90  count_var_91  \\\n",
       "153248   4.9254  13.1096      ...                  1            68   \n",
       "67802    4.4437   6.8451      ...                  1            48   \n",
       "148889   2.8893   8.7265      ...                  2            61   \n",
       "103093   3.4052  10.0054      ...                  4            66   \n",
       "104681   4.4376   7.7387      ...                  4            57   \n",
       "80115    3.1575   8.5914      ...                  4            87   \n",
       "38121    3.9988   7.5953      ...                  2            65   \n",
       "121094   3.0204   8.2641      ...                  3            73   \n",
       "182119   3.5377   8.1789      ...                  1            76   \n",
       "48981    4.4646  10.7835      ...                  1            74   \n",
       "84264    4.1220  10.1944      ...                  2             3   \n",
       "15044    4.3556   6.6317      ...                  3            70   \n",
       "11425    4.2216   8.3073      ...                  3            65   \n",
       "161109   5.3309  10.2524      ...                  1             6   \n",
       "74171    4.0187   8.5123      ...                  1            54   \n",
       "67739    3.5373   9.0176      ...                  1            42   \n",
       "80755    3.6242   7.4505      ...                  2            61   \n",
       "138008   4.0651   9.2716      ...                  1            59   \n",
       "17267    3.3875   9.4389      ...                  1            48   \n",
       "72712    4.7375  11.4684      ...                  1            35   \n",
       "26976    5.0314  10.7592      ...                  3            17   \n",
       "181576   4.4438   8.6863      ...                  2            22   \n",
       "194759   3.3775   4.7318      ...                  1            62   \n",
       "4252     5.8225   9.8007      ...                  1            36   \n",
       "62392    4.3392  10.6411      ...                  1            72   \n",
       "179546   3.5447  11.3310      ...                  1            71   \n",
       "181416   4.2544   7.9608      ...                  2            46   \n",
       "97890    4.1289   9.6520      ...                  2            68   \n",
       "116273   4.1129   7.2264      ...                  1            45   \n",
       "22851    4.2378   9.3349      ...                  2            32   \n",
       "...         ...      ...      ...                ...           ...   \n",
       "156730   5.0352   8.7784      ...                  1            51   \n",
       "130608   4.1264  12.6660      ...                  3            61   \n",
       "159765   4.8448  11.7098      ...                  2            66   \n",
       "85305    3.1102   9.3830      ...                  1            74   \n",
       "184779   2.9977  10.6633      ...                  1            67   \n",
       "103355   3.4931   4.9840      ...                  1            75   \n",
       "5311     6.1262   9.8388      ...                  2            65   \n",
       "199041   3.9157   9.1331      ...                  7            46   \n",
       "64925    4.2153   7.7219      ...                  1            19   \n",
       "194027   4.0466   9.2830      ...                  1            66   \n",
       "59735    3.7860   6.6762      ...                  2            68   \n",
       "769      4.1402   5.5864      ...                  2             4   \n",
       "64820    5.4093  10.0675      ...                  4            58   \n",
       "67221    3.2814  10.1917      ...                  6            62   \n",
       "41090    5.0589   9.9539      ...                  2            65   \n",
       "16023    3.2678  10.5745      ...                  1            73   \n",
       "191335   3.5991   8.2905      ...                  2            55   \n",
       "175203   4.0009   7.9658      ...                  1            56   \n",
       "126324   4.5149   5.0712      ...                  1            56   \n",
       "112727   5.3719  10.2320      ...                  2            63   \n",
       "87498    4.5260   7.7344      ...                  1            63   \n",
       "168266   2.5343   7.9942      ...                  3            63   \n",
       "137337   3.4787   9.3370      ...                  2            51   \n",
       "54886    3.6831   6.5588      ...                  1            54   \n",
       "110268   5.0181   6.2502      ...                  2            39   \n",
       "119879   3.5605   6.9004      ...                  1            54   \n",
       "103694   4.7741   9.3372      ...                  1            71   \n",
       "131932   3.2504   6.9852      ...                  1            55   \n",
       "146867   3.1573   8.6953      ...                  2            54   \n",
       "121958   4.7322   6.0260      ...                  1            36   \n",
       "\n",
       "        count_var_92  count_var_93  count_var_94  count_var_95  count_var_96  \\\n",
       "153248             3            25             3            14             1   \n",
       "67802              4            14             4             2             5   \n",
       "148889             6            20            10            17             4   \n",
       "103093             2            19             3            15             1   \n",
       "104681             6             5             6            13             1   \n",
       "80115              4            15             3            15             2   \n",
       "38121              8            25            10            19             2   \n",
       "121094             3            22             2            11             1   \n",
       "182119             1            15             7            17             3   \n",
       "48981              2            10             3             4             1   \n",
       "84264              4            16             2            16             2   \n",
       "15044              3            12             4            17             3   \n",
       "11425              3             7             3            21             2   \n",
       "161109             3             2             2             2             3   \n",
       "74171              4            17             5             7             2   \n",
       "67739              2            13             5            13             2   \n",
       "80755              1            17             3            16             3   \n",
       "138008             1            22             5             3             1   \n",
       "17267              3            20             4            13             2   \n",
       "72712              3            15             5            10             2   \n",
       "26976              2            16             3            10             2   \n",
       "181576             5            26             5            21             3   \n",
       "194759             3            23             2            22             2   \n",
       "4252               2             5             2            13             1   \n",
       "62392              1            23             3             1             1   \n",
       "179546             3             4             7            18             1   \n",
       "181416             4            19             9             8             1   \n",
       "97890              2             6             6            22             1   \n",
       "116273             1            14             5             9             3   \n",
       "22851              2            12             4             6             3   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "156730             2            22             4            13             3   \n",
       "130608             4            25             5             9             1   \n",
       "159765             6            24             4            15             1   \n",
       "85305              6             6             3            17             2   \n",
       "184779             4            22             4            21             2   \n",
       "103355             2            20             6            23             1   \n",
       "5311               1            22             2            14             2   \n",
       "199041             2            25             3             1             2   \n",
       "64925              5            27             5            25             2   \n",
       "194027             3            21             6            13             4   \n",
       "59735              5            15             2            20             1   \n",
       "769                3            15             7            22             1   \n",
       "64820              5            14             9            21             3   \n",
       "67221              5            14            10            24             6   \n",
       "41090              3            27             2            13             2   \n",
       "16023              6            12             6            21             2   \n",
       "191335             6            17             3            11             2   \n",
       "175203             4            23             1            15             1   \n",
       "126324             3            23            10            17             1   \n",
       "112727             2            15             7            12             2   \n",
       "87498              3            10             2             8             1   \n",
       "168266             5            23             2            19             1   \n",
       "137337             2            15             1            13             2   \n",
       "54886              4            14             4            21             1   \n",
       "110268             2             3             7            25             1   \n",
       "119879             4            11             4            18             2   \n",
       "103694             2            19             5            20             1   \n",
       "131932             2            18             4            16             2   \n",
       "146867             4            24             7            20             2   \n",
       "121958             3            10             5            10             2   \n",
       "\n",
       "        count_var_97  count_var_98  count_var_99  \n",
       "153248             1             2            13  \n",
       "67802              1             6             8  \n",
       "148889             2            22             8  \n",
       "103093             3            15             6  \n",
       "104681             2            17            11  \n",
       "80115              1            12             8  \n",
       "38121              1            13             1  \n",
       "121094             1            16             4  \n",
       "182119             1            14             3  \n",
       "48981              5            11             4  \n",
       "84264              1            20             6  \n",
       "15044              3             9             4  \n",
       "11425              2            15             2  \n",
       "161109             1            15             8  \n",
       "74171              2             9             6  \n",
       "67739              3            19             7  \n",
       "80755              3            12             8  \n",
       "138008             1            19             2  \n",
       "17267              1            14             9  \n",
       "72712              1             4             6  \n",
       "26976              1            10             5  \n",
       "181576             1             8             6  \n",
       "194759             2            16             6  \n",
       "4252               3            16             2  \n",
       "62392              3            12             1  \n",
       "179546             3            17             7  \n",
       "181416             2             7             8  \n",
       "97890              1             8             5  \n",
       "116273             3            14             1  \n",
       "22851              2            12             2  \n",
       "...              ...           ...           ...  \n",
       "156730             2            13             3  \n",
       "130608             2            17             3  \n",
       "159765             3             9             2  \n",
       "85305              1            16             6  \n",
       "184779             2            10             4  \n",
       "103355             1            15             5  \n",
       "5311               4            13             6  \n",
       "199041             2             3             1  \n",
       "64925              1            17             6  \n",
       "194027             2            18             4  \n",
       "59735              5            18             6  \n",
       "769                2            22             1  \n",
       "64820              1             5            10  \n",
       "67221              1            15             8  \n",
       "41090              3            15             6  \n",
       "16023              2             8             4  \n",
       "191335             1            19            10  \n",
       "175203             1             5             4  \n",
       "126324             1            16             9  \n",
       "112727             1            16             4  \n",
       "87498              2            19             4  \n",
       "168266             1             3             6  \n",
       "137337             2             1             3  \n",
       "54886              2            21             6  \n",
       "110268             3            13             5  \n",
       "119879             1             1             4  \n",
       "103694             1            12             4  \n",
       "131932             1            19             8  \n",
       "146867             4            22             2  \n",
       "121958             2             5             7  \n",
       "\n",
       "[160000 rows x 400 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a725309d39e49aea0264084433f289b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968671\tvalid_1's auc: 0.89846\n",
      "[10000]\ttraining's auc: 0.98931\tvalid_1's auc: 0.902326\n",
      "[15000]\ttraining's auc: 0.997391\tvalid_1's auc: 0.903098\n",
      "[20000]\ttraining's auc: 0.999543\tvalid_1's auc: 0.903235\n",
      "[25000]\ttraining's auc: 0.999934\tvalid_1's auc: 0.903181\n",
      "Early stopping, best iteration is:\n",
      "[21383]\ttraining's auc: 0.999729\tvalid_1's auc: 0.903392\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968954\tvalid_1's auc: 0.901085\n",
      "[10000]\ttraining's auc: 0.989544\tvalid_1's auc: 0.903016\n",
      "[15000]\ttraining's auc: 0.997488\tvalid_1's auc: 0.903607\n",
      "[20000]\ttraining's auc: 0.999569\tvalid_1's auc: 0.903708\n",
      "Early stopping, best iteration is:\n",
      "[19083]\ttraining's auc: 0.999395\tvalid_1's auc: 0.903795\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.969112\tvalid_1's auc: 0.900041\n",
      "[10000]\ttraining's auc: 0.989604\tvalid_1's auc: 0.901714\n",
      "[15000]\ttraining's auc: 0.99751\tvalid_1's auc: 0.901976\n",
      "[20000]\ttraining's auc: 0.999572\tvalid_1's auc: 0.901911\n",
      "Early stopping, best iteration is:\n",
      "[17115]\ttraining's auc: 0.998769\tvalid_1's auc: 0.902081\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968847\tvalid_1's auc: 0.897044\n",
      "[10000]\ttraining's auc: 0.989358\tvalid_1's auc: 0.900107\n",
      "[15000]\ttraining's auc: 0.997371\tvalid_1's auc: 0.900767\n",
      "[20000]\ttraining's auc: 0.999531\tvalid_1's auc: 0.901104\n",
      "[25000]\ttraining's auc: 0.999937\tvalid_1's auc: 0.901258\n",
      "[30000]\ttraining's auc: 0.999992\tvalid_1's auc: 0.901408\n",
      "Early stopping, best iteration is:\n",
      "[28735]\ttraining's auc: 0.999987\tvalid_1's auc: 0.901535\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968977\tvalid_1's auc: 0.896869\n",
      "[10000]\ttraining's auc: 0.989519\tvalid_1's auc: 0.898248\n",
      "Early stopping, best iteration is:\n",
      "[10485]\ttraining's auc: 0.990733\tvalid_1's auc: 0.898331\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968793\tvalid_1's auc: 0.899143\n",
      "[10000]\ttraining's auc: 0.98943\tvalid_1's auc: 0.901283\n",
      "[15000]\ttraining's auc: 0.997439\tvalid_1's auc: 0.901781\n",
      "Early stopping, best iteration is:\n",
      "[15268]\ttraining's auc: 0.997642\tvalid_1's auc: 0.90183\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.9691\tvalid_1's auc: 0.897803\n",
      "[10000]\ttraining's auc: 0.989532\tvalid_1's auc: 0.89958\n",
      "[15000]\ttraining's auc: 0.997458\tvalid_1's auc: 0.899864\n",
      "Early stopping, best iteration is:\n",
      "[15205]\ttraining's auc: 0.997616\tvalid_1's auc: 0.899946\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968974\tvalid_1's auc: 0.898151\n",
      "[10000]\ttraining's auc: 0.989516\tvalid_1's auc: 0.900992\n",
      "[15000]\ttraining's auc: 0.997491\tvalid_1's auc: 0.901676\n",
      "[20000]\ttraining's auc: 0.999563\tvalid_1's auc: 0.901768\n",
      "Early stopping, best iteration is:\n",
      "[18535]\ttraining's auc: 0.999249\tvalid_1's auc: 0.901878\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968701\tvalid_1's auc: 0.904197\n",
      "[10000]\ttraining's auc: 0.989411\tvalid_1's auc: 0.906651\n",
      "[15000]\ttraining's auc: 0.997452\tvalid_1's auc: 0.906862\n",
      "Early stopping, best iteration is:\n",
      "[12729]\ttraining's auc: 0.994927\tvalid_1's auc: 0.907017\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.96868\tvalid_1's auc: 0.90403\n",
      "[10000]\ttraining's auc: 0.989417\tvalid_1's auc: 0.906226\n",
      "[15000]\ttraining's auc: 0.997442\tvalid_1's auc: 0.906168\n",
      "Early stopping, best iteration is:\n",
      "[11247]\ttraining's auc: 0.992351\tvalid_1's auc: 0.906417\n"
     ]
    }
   ],
   "source": [
    "rank_models = lgb_trainer_no_aug(Xtr, ytr, param, n_folds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21536fdc4324a8e8c15df229313b5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968671\tvalid_1's auc: 0.89846\n",
      "[10000]\ttraining's auc: 0.98931\tvalid_1's auc: 0.902326\n",
      "[15000]\ttraining's auc: 0.997391\tvalid_1's auc: 0.903098\n",
      "[20000]\ttraining's auc: 0.999543\tvalid_1's auc: 0.903235\n",
      "[25000]\ttraining's auc: 0.999934\tvalid_1's auc: 0.903181\n",
      "Early stopping, best iteration is:\n",
      "[21383]\ttraining's auc: 0.999729\tvalid_1's auc: 0.903392\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968954\tvalid_1's auc: 0.901085\n",
      "[10000]\ttraining's auc: 0.989544\tvalid_1's auc: 0.903016\n",
      "[15000]\ttraining's auc: 0.997488\tvalid_1's auc: 0.903607\n",
      "[20000]\ttraining's auc: 0.999569\tvalid_1's auc: 0.903708\n",
      "Early stopping, best iteration is:\n",
      "[19083]\ttraining's auc: 0.999395\tvalid_1's auc: 0.903795\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.969112\tvalid_1's auc: 0.900041\n",
      "[10000]\ttraining's auc: 0.989604\tvalid_1's auc: 0.901714\n",
      "[15000]\ttraining's auc: 0.99751\tvalid_1's auc: 0.901976\n",
      "[20000]\ttraining's auc: 0.999572\tvalid_1's auc: 0.901911\n",
      "Early stopping, best iteration is:\n",
      "[17115]\ttraining's auc: 0.998769\tvalid_1's auc: 0.902081\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968847\tvalid_1's auc: 0.897044\n",
      "[10000]\ttraining's auc: 0.989358\tvalid_1's auc: 0.900107\n",
      "[15000]\ttraining's auc: 0.997371\tvalid_1's auc: 0.900767\n",
      "[20000]\ttraining's auc: 0.999531\tvalid_1's auc: 0.901104\n",
      "[25000]\ttraining's auc: 0.999937\tvalid_1's auc: 0.901258\n",
      "[30000]\ttraining's auc: 0.999992\tvalid_1's auc: 0.901408\n",
      "Early stopping, best iteration is:\n",
      "[28735]\ttraining's auc: 0.999987\tvalid_1's auc: 0.901535\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968977\tvalid_1's auc: 0.896869\n",
      "[10000]\ttraining's auc: 0.989519\tvalid_1's auc: 0.898248\n",
      "Early stopping, best iteration is:\n",
      "[10485]\ttraining's auc: 0.990733\tvalid_1's auc: 0.898331\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968793\tvalid_1's auc: 0.899143\n",
      "[10000]\ttraining's auc: 0.98943\tvalid_1's auc: 0.901283\n",
      "[15000]\ttraining's auc: 0.997439\tvalid_1's auc: 0.901781\n",
      "Early stopping, best iteration is:\n",
      "[15268]\ttraining's auc: 0.997642\tvalid_1's auc: 0.90183\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.9691\tvalid_1's auc: 0.897803\n",
      "[10000]\ttraining's auc: 0.989532\tvalid_1's auc: 0.89958\n",
      "[15000]\ttraining's auc: 0.997458\tvalid_1's auc: 0.899864\n",
      "Early stopping, best iteration is:\n",
      "[15205]\ttraining's auc: 0.997616\tvalid_1's auc: 0.899946\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968974\tvalid_1's auc: 0.898151\n",
      "[10000]\ttraining's auc: 0.989516\tvalid_1's auc: 0.900992\n",
      "[15000]\ttraining's auc: 0.997491\tvalid_1's auc: 0.901676\n",
      "[20000]\ttraining's auc: 0.999563\tvalid_1's auc: 0.901768\n",
      "Early stopping, best iteration is:\n",
      "[18535]\ttraining's auc: 0.999249\tvalid_1's auc: 0.901878\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.968701\tvalid_1's auc: 0.904197\n",
      "[10000]\ttraining's auc: 0.989411\tvalid_1's auc: 0.906651\n",
      "[15000]\ttraining's auc: 0.997452\tvalid_1's auc: 0.906862\n",
      "Early stopping, best iteration is:\n",
      "[12729]\ttraining's auc: 0.994927\tvalid_1's auc: 0.907017\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.96868\tvalid_1's auc: 0.90403\n",
      "[10000]\ttraining's auc: 0.989417\tvalid_1's auc: 0.906226\n",
      "[15000]\ttraining's auc: 0.997442\tvalid_1's auc: 0.906168\n",
      "Early stopping, best iteration is:\n",
      "[11247]\ttraining's auc: 0.992351\tvalid_1's auc: 0.906417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rank_models = lgb_trainer_no_aug(Xtr, ytr, param, n_folds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 \t Score: 0.9020389947581418\n",
      "Fold: 1 \t Score: 0.902182705005108\n",
      "Fold: 2 \t Score: 0.9014633039769626\n",
      "Fold: 3 \t Score: 0.9023763966956475\n",
      "Fold: 4 \t Score: 0.9017230687972748\n",
      "Fold: 5 \t Score: 0.9015229390725862\n",
      "Fold: 6 \t Score: 0.9018484235086522\n",
      "Fold: 7 \t Score: 0.9022023182348017\n",
      "Fold: 8 \t Score: 0.901656132277495\n",
      "Fold: 9 \t Score: 0.9016882612631216\n",
      "Score: 0.902924996065967\n"
     ]
    }
   ],
   "source": [
    "scorre, q, w = test_f(Xval, yval, rank_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023425</td>\n",
       "      <td>0.025546</td>\n",
       "      <td>0.027461</td>\n",
       "      <td>0.010824</td>\n",
       "      <td>0.033146</td>\n",
       "      <td>0.027883</td>\n",
       "      <td>0.030802</td>\n",
       "      <td>0.026918</td>\n",
       "      <td>0.028467</td>\n",
       "      <td>0.039955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.005701</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.010890</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.005713</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.006498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008951</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>0.008897</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>0.009488</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>0.016142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.603901</td>\n",
       "      <td>0.603392</td>\n",
       "      <td>0.571978</td>\n",
       "      <td>0.671681</td>\n",
       "      <td>0.582038</td>\n",
       "      <td>0.560688</td>\n",
       "      <td>0.537799</td>\n",
       "      <td>0.578163</td>\n",
       "      <td>0.558905</td>\n",
       "      <td>0.531581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.061122</td>\n",
       "      <td>0.050704</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.040980</td>\n",
       "      <td>0.073177</td>\n",
       "      <td>0.060327</td>\n",
       "      <td>0.051676</td>\n",
       "      <td>0.069769</td>\n",
       "      <td>0.059749</td>\n",
       "      <td>0.080979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.001513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.486930</td>\n",
       "      <td>0.457319</td>\n",
       "      <td>0.443678</td>\n",
       "      <td>0.433558</td>\n",
       "      <td>0.373163</td>\n",
       "      <td>0.414060</td>\n",
       "      <td>0.572944</td>\n",
       "      <td>0.455553</td>\n",
       "      <td>0.477172</td>\n",
       "      <td>0.411644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007669</td>\n",
       "      <td>0.009688</td>\n",
       "      <td>0.010691</td>\n",
       "      <td>0.006937</td>\n",
       "      <td>0.016473</td>\n",
       "      <td>0.010871</td>\n",
       "      <td>0.011947</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>0.014376</td>\n",
       "      <td>0.016697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.001963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.054043</td>\n",
       "      <td>0.053256</td>\n",
       "      <td>0.069695</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>0.089481</td>\n",
       "      <td>0.062144</td>\n",
       "      <td>0.077016</td>\n",
       "      <td>0.059335</td>\n",
       "      <td>0.058001</td>\n",
       "      <td>0.067015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>0.011907</td>\n",
       "      <td>0.010034</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.013983</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.010191</td>\n",
       "      <td>0.013430</td>\n",
       "      <td>0.013086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.176139</td>\n",
       "      <td>0.148621</td>\n",
       "      <td>0.135667</td>\n",
       "      <td>0.133110</td>\n",
       "      <td>0.173982</td>\n",
       "      <td>0.215340</td>\n",
       "      <td>0.172763</td>\n",
       "      <td>0.140663</td>\n",
       "      <td>0.140147</td>\n",
       "      <td>0.185684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.037688</td>\n",
       "      <td>0.042301</td>\n",
       "      <td>0.042441</td>\n",
       "      <td>0.020668</td>\n",
       "      <td>0.066736</td>\n",
       "      <td>0.044404</td>\n",
       "      <td>0.042542</td>\n",
       "      <td>0.052286</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>0.041652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.008867</td>\n",
       "      <td>0.008672</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>0.016425</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>0.009336</td>\n",
       "      <td>0.011308</td>\n",
       "      <td>0.016683</td>\n",
       "      <td>0.013778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.006439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.115930</td>\n",
       "      <td>0.161601</td>\n",
       "      <td>0.161388</td>\n",
       "      <td>0.107225</td>\n",
       "      <td>0.151578</td>\n",
       "      <td>0.145726</td>\n",
       "      <td>0.169249</td>\n",
       "      <td>0.153463</td>\n",
       "      <td>0.189014</td>\n",
       "      <td>0.178875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.019490</td>\n",
       "      <td>0.024725</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>0.018203</td>\n",
       "      <td>0.035475</td>\n",
       "      <td>0.026178</td>\n",
       "      <td>0.022767</td>\n",
       "      <td>0.031648</td>\n",
       "      <td>0.025229</td>\n",
       "      <td>0.026723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.060868</td>\n",
       "      <td>0.046741</td>\n",
       "      <td>0.043923</td>\n",
       "      <td>0.061248</td>\n",
       "      <td>0.066827</td>\n",
       "      <td>0.056087</td>\n",
       "      <td>0.050764</td>\n",
       "      <td>0.059989</td>\n",
       "      <td>0.055689</td>\n",
       "      <td>0.058558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.007762</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.010750</td>\n",
       "      <td>0.004981</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.011138</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>0.011640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.006933</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.011470</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.008050</td>\n",
       "      <td>0.007667</td>\n",
       "      <td>0.010520</td>\n",
       "      <td>0.013517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>0.002688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.043565</td>\n",
       "      <td>0.036867</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.033506</td>\n",
       "      <td>0.061895</td>\n",
       "      <td>0.059252</td>\n",
       "      <td>0.053088</td>\n",
       "      <td>0.038845</td>\n",
       "      <td>0.047507</td>\n",
       "      <td>0.054023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.020105</td>\n",
       "      <td>0.022334</td>\n",
       "      <td>0.033028</td>\n",
       "      <td>0.026767</td>\n",
       "      <td>0.042872</td>\n",
       "      <td>0.032408</td>\n",
       "      <td>0.036787</td>\n",
       "      <td>0.027734</td>\n",
       "      <td>0.033119</td>\n",
       "      <td>0.043987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.053132</td>\n",
       "      <td>0.054036</td>\n",
       "      <td>0.052450</td>\n",
       "      <td>0.052251</td>\n",
       "      <td>0.067873</td>\n",
       "      <td>0.051448</td>\n",
       "      <td>0.061853</td>\n",
       "      <td>0.048559</td>\n",
       "      <td>0.073807</td>\n",
       "      <td>0.065831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.248944</td>\n",
       "      <td>0.270753</td>\n",
       "      <td>0.248063</td>\n",
       "      <td>0.198545</td>\n",
       "      <td>0.280230</td>\n",
       "      <td>0.286988</td>\n",
       "      <td>0.292806</td>\n",
       "      <td>0.260158</td>\n",
       "      <td>0.258329</td>\n",
       "      <td>0.275128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.325865</td>\n",
       "      <td>0.379992</td>\n",
       "      <td>0.323457</td>\n",
       "      <td>0.345224</td>\n",
       "      <td>0.335808</td>\n",
       "      <td>0.348284</td>\n",
       "      <td>0.349766</td>\n",
       "      <td>0.298876</td>\n",
       "      <td>0.361075</td>\n",
       "      <td>0.386026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.011270</td>\n",
       "      <td>0.008727</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.014308</td>\n",
       "      <td>0.012430</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.010755</td>\n",
       "      <td>0.012064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.064675</td>\n",
       "      <td>0.069139</td>\n",
       "      <td>0.074453</td>\n",
       "      <td>0.054751</td>\n",
       "      <td>0.072925</td>\n",
       "      <td>0.061011</td>\n",
       "      <td>0.048577</td>\n",
       "      <td>0.054099</td>\n",
       "      <td>0.083947</td>\n",
       "      <td>0.075693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.004564</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.004853</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.006825</td>\n",
       "      <td>0.008815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39970</th>\n",
       "      <td>0.011103</td>\n",
       "      <td>0.015551</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0.007813</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.017451</td>\n",
       "      <td>0.012859</td>\n",
       "      <td>0.011296</td>\n",
       "      <td>0.022107</td>\n",
       "      <td>0.021520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39971</th>\n",
       "      <td>0.065027</td>\n",
       "      <td>0.052367</td>\n",
       "      <td>0.047722</td>\n",
       "      <td>0.044432</td>\n",
       "      <td>0.072357</td>\n",
       "      <td>0.055012</td>\n",
       "      <td>0.063811</td>\n",
       "      <td>0.050570</td>\n",
       "      <td>0.049673</td>\n",
       "      <td>0.061995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39972</th>\n",
       "      <td>0.013375</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.022076</td>\n",
       "      <td>0.026983</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>0.016758</td>\n",
       "      <td>0.020389</td>\n",
       "      <td>0.024858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39973</th>\n",
       "      <td>0.211014</td>\n",
       "      <td>0.201959</td>\n",
       "      <td>0.175529</td>\n",
       "      <td>0.216831</td>\n",
       "      <td>0.177230</td>\n",
       "      <td>0.223474</td>\n",
       "      <td>0.185665</td>\n",
       "      <td>0.201318</td>\n",
       "      <td>0.186948</td>\n",
       "      <td>0.183384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39974</th>\n",
       "      <td>0.022893</td>\n",
       "      <td>0.033039</td>\n",
       "      <td>0.026875</td>\n",
       "      <td>0.018317</td>\n",
       "      <td>0.050598</td>\n",
       "      <td>0.025324</td>\n",
       "      <td>0.026206</td>\n",
       "      <td>0.023770</td>\n",
       "      <td>0.031825</td>\n",
       "      <td>0.036471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39975</th>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.002164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39976</th>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.006061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39977</th>\n",
       "      <td>0.081739</td>\n",
       "      <td>0.103336</td>\n",
       "      <td>0.084852</td>\n",
       "      <td>0.060693</td>\n",
       "      <td>0.134939</td>\n",
       "      <td>0.137468</td>\n",
       "      <td>0.126443</td>\n",
       "      <td>0.105277</td>\n",
       "      <td>0.135132</td>\n",
       "      <td>0.117398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39978</th>\n",
       "      <td>0.009220</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.013705</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>0.020772</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>0.012728</td>\n",
       "      <td>0.017630</td>\n",
       "      <td>0.014822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39979</th>\n",
       "      <td>0.718263</td>\n",
       "      <td>0.626910</td>\n",
       "      <td>0.735071</td>\n",
       "      <td>0.793976</td>\n",
       "      <td>0.574706</td>\n",
       "      <td>0.674629</td>\n",
       "      <td>0.639087</td>\n",
       "      <td>0.712045</td>\n",
       "      <td>0.614713</td>\n",
       "      <td>0.694904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39980</th>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.005219</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.008353</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.007174</td>\n",
       "      <td>0.006134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39981</th>\n",
       "      <td>0.248917</td>\n",
       "      <td>0.203228</td>\n",
       "      <td>0.177869</td>\n",
       "      <td>0.185899</td>\n",
       "      <td>0.241991</td>\n",
       "      <td>0.194799</td>\n",
       "      <td>0.219269</td>\n",
       "      <td>0.188632</td>\n",
       "      <td>0.239221</td>\n",
       "      <td>0.229814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39982</th>\n",
       "      <td>0.007373</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>0.011907</td>\n",
       "      <td>0.006476</td>\n",
       "      <td>0.013673</td>\n",
       "      <td>0.009966</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>0.009742</td>\n",
       "      <td>0.013122</td>\n",
       "      <td>0.013033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39983</th>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.010114</td>\n",
       "      <td>0.006971</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.007063</td>\n",
       "      <td>0.008512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39984</th>\n",
       "      <td>0.007264</td>\n",
       "      <td>0.009883</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.012338</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>0.015712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39985</th>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.010217</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.009836</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>0.005760</td>\n",
       "      <td>0.010233</td>\n",
       "      <td>0.013262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39986</th>\n",
       "      <td>0.018306</td>\n",
       "      <td>0.022652</td>\n",
       "      <td>0.029319</td>\n",
       "      <td>0.023144</td>\n",
       "      <td>0.035669</td>\n",
       "      <td>0.024937</td>\n",
       "      <td>0.026525</td>\n",
       "      <td>0.022709</td>\n",
       "      <td>0.036313</td>\n",
       "      <td>0.038245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39987</th>\n",
       "      <td>0.042145</td>\n",
       "      <td>0.039906</td>\n",
       "      <td>0.041595</td>\n",
       "      <td>0.033034</td>\n",
       "      <td>0.053989</td>\n",
       "      <td>0.045580</td>\n",
       "      <td>0.051390</td>\n",
       "      <td>0.031967</td>\n",
       "      <td>0.047386</td>\n",
       "      <td>0.057329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39988</th>\n",
       "      <td>0.014063</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>0.013613</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.015414</td>\n",
       "      <td>0.015099</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.012806</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.017751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39989</th>\n",
       "      <td>0.479298</td>\n",
       "      <td>0.417672</td>\n",
       "      <td>0.445070</td>\n",
       "      <td>0.481194</td>\n",
       "      <td>0.414900</td>\n",
       "      <td>0.507162</td>\n",
       "      <td>0.510870</td>\n",
       "      <td>0.485689</td>\n",
       "      <td>0.398044</td>\n",
       "      <td>0.368033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39990</th>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.008423</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.007923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39991</th>\n",
       "      <td>0.079638</td>\n",
       "      <td>0.062408</td>\n",
       "      <td>0.087896</td>\n",
       "      <td>0.056877</td>\n",
       "      <td>0.103354</td>\n",
       "      <td>0.074777</td>\n",
       "      <td>0.069653</td>\n",
       "      <td>0.086606</td>\n",
       "      <td>0.079965</td>\n",
       "      <td>0.092982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39992</th>\n",
       "      <td>0.017667</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>0.016190</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.024436</td>\n",
       "      <td>0.016925</td>\n",
       "      <td>0.017880</td>\n",
       "      <td>0.014041</td>\n",
       "      <td>0.019038</td>\n",
       "      <td>0.023047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39993</th>\n",
       "      <td>0.110921</td>\n",
       "      <td>0.080926</td>\n",
       "      <td>0.130698</td>\n",
       "      <td>0.087270</td>\n",
       "      <td>0.174490</td>\n",
       "      <td>0.140954</td>\n",
       "      <td>0.137497</td>\n",
       "      <td>0.123947</td>\n",
       "      <td>0.170475</td>\n",
       "      <td>0.163367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39994</th>\n",
       "      <td>0.011625</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.007886</td>\n",
       "      <td>0.020731</td>\n",
       "      <td>0.016260</td>\n",
       "      <td>0.016716</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.017251</td>\n",
       "      <td>0.020194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>0.018076</td>\n",
       "      <td>0.018859</td>\n",
       "      <td>0.018546</td>\n",
       "      <td>0.015749</td>\n",
       "      <td>0.036495</td>\n",
       "      <td>0.023497</td>\n",
       "      <td>0.022987</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.026522</td>\n",
       "      <td>0.025703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.004921</td>\n",
       "      <td>0.005524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>0.061154</td>\n",
       "      <td>0.060936</td>\n",
       "      <td>0.064905</td>\n",
       "      <td>0.069767</td>\n",
       "      <td>0.075635</td>\n",
       "      <td>0.080119</td>\n",
       "      <td>0.065987</td>\n",
       "      <td>0.079584</td>\n",
       "      <td>0.082234</td>\n",
       "      <td>0.074197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>0.418198</td>\n",
       "      <td>0.363194</td>\n",
       "      <td>0.320579</td>\n",
       "      <td>0.374572</td>\n",
       "      <td>0.402464</td>\n",
       "      <td>0.364602</td>\n",
       "      <td>0.351601</td>\n",
       "      <td>0.384334</td>\n",
       "      <td>0.400911</td>\n",
       "      <td>0.389024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>0.010658</td>\n",
       "      <td>0.010468</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.021599</td>\n",
       "      <td>0.011049</td>\n",
       "      <td>0.013456</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>0.015070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.000305  0.000331  0.000438  0.000156  0.001096  0.000553  0.000475   \n",
       "1      0.023425  0.025546  0.027461  0.010824  0.033146  0.027883  0.030802   \n",
       "2      0.005400  0.004067  0.005701  0.002598  0.010890  0.005298  0.005713   \n",
       "3      0.008951  0.007750  0.008897  0.003479  0.015060  0.007753  0.009488   \n",
       "4      0.603901  0.603392  0.571978  0.671681  0.582038  0.560688  0.537799   \n",
       "5      0.061122  0.050704  0.043100  0.040980  0.073177  0.060327  0.051676   \n",
       "6      0.000448  0.000498  0.000586  0.000273  0.001257  0.000667  0.000796   \n",
       "7      0.486930  0.457319  0.443678  0.433558  0.373163  0.414060  0.572944   \n",
       "8      0.007669  0.009688  0.010691  0.006937  0.016473  0.010871  0.011947   \n",
       "9      0.000906  0.000824  0.001100  0.000779  0.001899  0.001291  0.001248   \n",
       "10     0.054043  0.053256  0.069695  0.033766  0.089481  0.062144  0.077016   \n",
       "11     0.013846  0.013496  0.011907  0.010034  0.017433  0.013983  0.014127   \n",
       "12     0.176139  0.148621  0.135667  0.133110  0.173982  0.215340  0.172763   \n",
       "13     0.037688  0.042301  0.042441  0.020668  0.066736  0.044404  0.042542   \n",
       "14     0.008867  0.008672  0.011471  0.007296  0.016425  0.012514  0.009336   \n",
       "15     0.003384  0.003523  0.004114  0.001994  0.007000  0.004537  0.003611   \n",
       "16     0.115930  0.161601  0.161388  0.107225  0.151578  0.145726  0.169249   \n",
       "17     0.019490  0.024725  0.034459  0.018203  0.035475  0.026178  0.022767   \n",
       "18     0.060868  0.046741  0.043923  0.061248  0.066827  0.056087  0.050764   \n",
       "19     0.007762  0.010714  0.010750  0.004981  0.018447  0.011138  0.008831   \n",
       "20     0.006255  0.006019  0.006933  0.004186  0.011470  0.008135  0.008050   \n",
       "21     0.001333  0.001452  0.001786  0.000673  0.003527  0.001633  0.002273   \n",
       "22     0.043565  0.036867  0.051000  0.033506  0.061895  0.059252  0.053088   \n",
       "23     0.020105  0.022334  0.033028  0.026767  0.042872  0.032408  0.036787   \n",
       "24     0.053132  0.054036  0.052450  0.052251  0.067873  0.051448  0.061853   \n",
       "25     0.248944  0.270753  0.248063  0.198545  0.280230  0.286988  0.292806   \n",
       "26     0.325865  0.379992  0.323457  0.345224  0.335808  0.348284  0.349766   \n",
       "27     0.011270  0.008727  0.009527  0.005134  0.014308  0.012430  0.012509   \n",
       "28     0.064675  0.069139  0.074453  0.054751  0.072925  0.061011  0.048577   \n",
       "29     0.004564  0.005560  0.005339  0.002835  0.007263  0.004853  0.005058   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "39970  0.011103  0.015551  0.017161  0.007813  0.021429  0.017451  0.012859   \n",
       "39971  0.065027  0.052367  0.047722  0.044432  0.072357  0.055012  0.063811   \n",
       "39972  0.013375  0.013500  0.012976  0.007635  0.022076  0.026983  0.014101   \n",
       "39973  0.211014  0.201959  0.175529  0.216831  0.177230  0.223474  0.185665   \n",
       "39974  0.022893  0.033039  0.026875  0.018317  0.050598  0.025324  0.026206   \n",
       "39975  0.000581  0.000876  0.000980  0.000577  0.001982  0.001058  0.001263   \n",
       "39976  0.002763  0.002146  0.003799  0.001380  0.006454  0.002821  0.002919   \n",
       "39977  0.081739  0.103336  0.084852  0.060693  0.134939  0.137468  0.126443   \n",
       "39978  0.009220  0.010363  0.013705  0.005626  0.020772  0.012130  0.014091   \n",
       "39979  0.718263  0.626910  0.735071  0.793976  0.574706  0.674629  0.639087   \n",
       "39980  0.003404  0.005219  0.004839  0.002621  0.008353  0.006098  0.006622   \n",
       "39981  0.248917  0.203228  0.177869  0.185899  0.241991  0.194799  0.219269   \n",
       "39982  0.007373  0.007611  0.011907  0.006476  0.013673  0.009966  0.013358   \n",
       "39983  0.004163  0.003551  0.005297  0.003765  0.010114  0.006971  0.005772   \n",
       "39984  0.007264  0.009883  0.010766  0.005574  0.015419  0.012338  0.009451   \n",
       "39985  0.006864  0.007619  0.010217  0.004863  0.011931  0.009836  0.008098   \n",
       "39986  0.018306  0.022652  0.029319  0.023144  0.035669  0.024937  0.026525   \n",
       "39987  0.042145  0.039906  0.041595  0.033034  0.053989  0.045580  0.051390   \n",
       "39988  0.014063  0.014251  0.013613  0.008202  0.015414  0.015099  0.011244   \n",
       "39989  0.479298  0.417672  0.445070  0.481194  0.414900  0.507162  0.510870   \n",
       "39990  0.003484  0.003689  0.005985  0.001863  0.008423  0.005969  0.005740   \n",
       "39991  0.079638  0.062408  0.087896  0.056877  0.103354  0.074777  0.069653   \n",
       "39992  0.017667  0.011374  0.016190  0.011593  0.024436  0.016925  0.017880   \n",
       "39993  0.110921  0.080926  0.130698  0.087270  0.174490  0.140954  0.137497   \n",
       "39994  0.011625  0.014262  0.014086  0.007886  0.020731  0.016260  0.016716   \n",
       "39995  0.018076  0.018859  0.018546  0.015749  0.036495  0.023497  0.022987   \n",
       "39996  0.002221  0.003135  0.002964  0.001936  0.006246  0.003706  0.002890   \n",
       "39997  0.061154  0.060936  0.064905  0.069767  0.075635  0.080119  0.065987   \n",
       "39998  0.418198  0.363194  0.320579  0.374572  0.402464  0.364602  0.351601   \n",
       "39999  0.010658  0.010468  0.014151  0.005782  0.021599  0.011049  0.013456   \n",
       "\n",
       "              7         8         9  \n",
       "0      0.000433  0.000778  0.000934  \n",
       "1      0.026918  0.028467  0.039955  \n",
       "2      0.003522  0.005787  0.006498  \n",
       "3      0.007531  0.009832  0.016142  \n",
       "4      0.578163  0.558905  0.531581  \n",
       "5      0.069769  0.059749  0.080979  \n",
       "6      0.000524  0.000848  0.001513  \n",
       "7      0.455553  0.477172  0.411644  \n",
       "8      0.011854  0.014376  0.016697  \n",
       "9      0.001106  0.001940  0.001963  \n",
       "10     0.059335  0.058001  0.067015  \n",
       "11     0.010191  0.013430  0.013086  \n",
       "12     0.140663  0.140147  0.185684  \n",
       "13     0.052286  0.037782  0.041652  \n",
       "14     0.011308  0.016683  0.013778  \n",
       "15     0.004580  0.005190  0.006439  \n",
       "16     0.153463  0.189014  0.178875  \n",
       "17     0.031648  0.025229  0.026723  \n",
       "18     0.059989  0.055689  0.058558  \n",
       "19     0.014760  0.014346  0.011640  \n",
       "20     0.007667  0.010520  0.013517  \n",
       "21     0.001059  0.002467  0.002688  \n",
       "22     0.038845  0.047507  0.054023  \n",
       "23     0.027734  0.033119  0.043987  \n",
       "24     0.048559  0.073807  0.065831  \n",
       "25     0.260158  0.258329  0.275128  \n",
       "26     0.298876  0.361075  0.386026  \n",
       "27     0.011657  0.010755  0.012064  \n",
       "28     0.054099  0.083947  0.075693  \n",
       "29     0.003852  0.006825  0.008815  \n",
       "...         ...       ...       ...  \n",
       "39970  0.011296  0.022107  0.021520  \n",
       "39971  0.050570  0.049673  0.061995  \n",
       "39972  0.016758  0.020389  0.024858  \n",
       "39973  0.201318  0.186948  0.183384  \n",
       "39974  0.023770  0.031825  0.036471  \n",
       "39975  0.000963  0.001445  0.002164  \n",
       "39976  0.002524  0.003291  0.006061  \n",
       "39977  0.105277  0.135132  0.117398  \n",
       "39978  0.012728  0.017630  0.014822  \n",
       "39979  0.712045  0.614713  0.694904  \n",
       "39980  0.004188  0.007174  0.006134  \n",
       "39981  0.188632  0.239221  0.229814  \n",
       "39982  0.009742  0.013122  0.013033  \n",
       "39983  0.004223  0.007063  0.008512  \n",
       "39984  0.013212  0.012955  0.015712  \n",
       "39985  0.005760  0.010233  0.013262  \n",
       "39986  0.022709  0.036313  0.038245  \n",
       "39987  0.031967  0.047386  0.057329  \n",
       "39988  0.012806  0.014948  0.017751  \n",
       "39989  0.485689  0.398044  0.368033  \n",
       "39990  0.003828  0.006158  0.007923  \n",
       "39991  0.086606  0.079965  0.092982  \n",
       "39992  0.014041  0.019038  0.023047  \n",
       "39993  0.123947  0.170475  0.163367  \n",
       "39994  0.013867  0.017251  0.020194  \n",
       "39995  0.016603  0.026522  0.025703  \n",
       "39996  0.002242  0.004921  0.005524  \n",
       "39997  0.079584  0.082234  0.074197  \n",
       "39998  0.384334  0.400911  0.389024  \n",
       "39999  0.010658  0.019009  0.015070  \n",
       "\n",
       "[40000 rows x 10 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(rank_models, 'ovvverrr.m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_answer(models, answer_qdf):\n",
    "    test_labels = answer_qdf.ID_code\n",
    "    answer_qdf = answer_qdf.drop(['ID_code'], axis=1)\n",
    "    y_preds = {}\n",
    "    for i, model in enumerate(tqdm(models)):\n",
    "            print(f\"On fold: {i}\")\n",
    "            y_preds[str(i)] = model.predict(answer_qdf)\n",
    "    y_preds = pd.DataFrame(y_preds)\n",
    "    answer_df = pd.DataFrame({\n",
    "        'ID_code' : test_labels,\n",
    "        'target' : y_preds.mean(axis = 1),\n",
    "        })\n",
    "    return answer_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c285b0051f1404186b70a8d1ba69bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ATEST = 'data/test.csv'\n",
    "test = pd.read_csv(ATEST)\n",
    "dftest = answer_agument(test, unique_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek= dftest.reindex(sorted(dftest.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "kek = dftest.rename(columns=lambda x: 'z' + str(x) if x[0] == 'c' else x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_10</th>\n",
       "      <th>var_100</th>\n",
       "      <th>var_101</th>\n",
       "      <th>var_102</th>\n",
       "      <th>var_103</th>\n",
       "      <th>var_104</th>\n",
       "      <th>var_105</th>\n",
       "      <th>...</th>\n",
       "      <th>zcount_var_90</th>\n",
       "      <th>zcount_var_91</th>\n",
       "      <th>zcount_var_92</th>\n",
       "      <th>zcount_var_93</th>\n",
       "      <th>zcount_var_94</th>\n",
       "      <th>zcount_var_95</th>\n",
       "      <th>zcount_var_96</th>\n",
       "      <th>zcount_var_97</th>\n",
       "      <th>zcount_var_98</th>\n",
       "      <th>zcount_var_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>-2.0248</td>\n",
       "      <td>-9.2198</td>\n",
       "      <td>17.3089</td>\n",
       "      <td>30.9548</td>\n",
       "      <td>1.4918</td>\n",
       "      <td>12.8721</td>\n",
       "      <td>3.4902</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>-1.3809</td>\n",
       "      <td>-1.7257</td>\n",
       "      <td>15.4712</td>\n",
       "      <td>35.6020</td>\n",
       "      <td>1.6570</td>\n",
       "      <td>13.0783</td>\n",
       "      <td>2.7752</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>-4.7057</td>\n",
       "      <td>-3.5065</td>\n",
       "      <td>14.1663</td>\n",
       "      <td>28.0256</td>\n",
       "      <td>1.3935</td>\n",
       "      <td>10.8257</td>\n",
       "      <td>4.2954</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>1.7021</td>\n",
       "      <td>2.5363</td>\n",
       "      <td>3.8763</td>\n",
       "      <td>1.5173</td>\n",
       "      <td>13.4083</td>\n",
       "      <td>2.8965</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>5.1025</td>\n",
       "      <td>-14.3858</td>\n",
       "      <td>17.8630</td>\n",
       "      <td>23.2274</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>14.4838</td>\n",
       "      <td>4.3806</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1  var_10  var_100  var_101  var_102  var_103  \\\n",
       "0  test_0  11.0656   7.7798 -2.0248  -9.2198  17.3089  30.9548   1.4918   \n",
       "1  test_1   8.5304   1.2543 -1.3809  -1.7257  15.4712  35.6020   1.6570   \n",
       "2  test_2   5.4827 -10.3581 -4.7057  -3.5065  14.1663  28.0256   1.3935   \n",
       "3  test_3   8.5374  -1.3222  0.0095   1.7021   2.5363   3.8763   1.5173   \n",
       "4  test_4  11.7058  -0.1327  5.1025 -14.3858  17.8630  23.2274   1.4375   \n",
       "\n",
       "   var_104  var_105      ...        zcount_var_90  zcount_var_91  \\\n",
       "0  12.8721   3.4902      ...                  1.0           54.0   \n",
       "1  13.0783   2.7752      ...                  1.0           39.0   \n",
       "2  10.8257   4.2954      ...                  1.0           71.0   \n",
       "3  13.4083   2.8965      ...                  1.0           62.0   \n",
       "4  14.4838   4.3806      ...                  2.0           69.0   \n",
       "\n",
       "   zcount_var_92  zcount_var_93  zcount_var_94  zcount_var_95  zcount_var_96  \\\n",
       "0            2.0           16.0            2.0           12.0            1.0   \n",
       "1            2.0           24.0            1.0           14.0            1.0   \n",
       "2           10.0            5.0            5.0           13.0            2.0   \n",
       "3            3.0           20.0            7.0           19.0            3.0   \n",
       "4            1.0           10.0            8.0           16.0            2.0   \n",
       "\n",
       "   zcount_var_97  zcount_var_98  zcount_var_99  \n",
       "0            1.0           17.0            4.0  \n",
       "1            2.0           19.0           10.0  \n",
       "2            2.0           11.0            4.0  \n",
       "3            1.0           15.0            5.0  \n",
       "4            1.0           10.0            3.0  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kek.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 401)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kek.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f5c60d54094905a33c759cc4f6b2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On fold: 0\n",
      "On fold: 1\n",
      "On fold: 2\n",
      "On fold: 3\n",
      "On fold: 4\n",
      "On fold: 5\n",
      "On fold: 6\n",
      "On fold: 7\n",
      "On fold: 8\n",
      "On fold: 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = make_answer(rank_models, kek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.052892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.131756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.147738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.224982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.048354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    target\n",
       "0  test_0  0.052892\n",
       "1  test_1  0.131756\n",
       "2  test_2  0.147738\n",
       "3  test_3  0.224982\n",
       "4  test_4  0.048354"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('answer_21_nunique_aug.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bayesian search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | learni... | min_da... | min_su... | num_le... | num_th... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.751413\tvalid_1's auc: 0.741352\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7414  \u001b[0m | \u001b[0m 0.5378  \u001b[0m | \u001b[0m 0.8561  \u001b[0m | \u001b[0m 0.007588\u001b[0m | \u001b[0m 143.8   \u001b[0m | \u001b[0m 6.56    \u001b[0m | \u001b[0m 10.46   \u001b[0m | \u001b[0m 6.232   \u001b[0m | \u001b[0m 0.8662  \u001b[0m | \u001b[0m 0.6011  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.856399\tvalid_1's auc: 0.839842\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.8398  \u001b[0m | \u001b[95m 0.3043  \u001b[0m | \u001b[95m 0.02832 \u001b[0m | \u001b[95m 0.009729\u001b[0m | \u001b[95m 176.5   \u001b[0m | \u001b[95m 7.123   \u001b[0m | \u001b[95m 11.36   \u001b[0m | \u001b[95m 6.734   \u001b[0m | \u001b[95m 0.3042  \u001b[0m | \u001b[95m 0.5248  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.820737\tvalid_1's auc: 0.808159\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8082  \u001b[0m | \u001b[0m 0.4976  \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 0.006507\u001b[0m | \u001b[0m 79.53   \u001b[0m | \u001b[0m 7.921   \u001b[0m | \u001b[0m 17.82   \u001b[0m | \u001b[0m 7.824   \u001b[0m | \u001b[0m 0.7852  \u001b[0m | \u001b[0m 0.1997  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[92]\ttraining's auc: 0.722399\tvalid_1's auc: 0.717617\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7176  \u001b[0m | \u001b[0m 0.44    \u001b[0m | \u001b[0m 0.5372  \u001b[0m | \u001b[0m 0.001418\u001b[0m | \u001b[0m 145.1   \u001b[0m | \u001b[0m 6.705   \u001b[0m | \u001b[0m 7.277   \u001b[0m | \u001b[0m 9.796   \u001b[0m | \u001b[0m 0.9656  \u001b[0m | \u001b[0m 0.8084  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.867238\tvalid_1's auc: 0.846849\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.8468  \u001b[0m | \u001b[95m 0.5868  \u001b[0m | \u001b[95m 0.09693 \u001b[0m | \u001b[95m 0.007158\u001b[0m | \u001b[95m 121.6   \u001b[0m | \u001b[95m 6.22    \u001b[0m | \u001b[95m 22.33   \u001b[0m | \u001b[95m 6.138   \u001b[0m | \u001b[95m 0.9093  \u001b[0m | \u001b[95m 0.2588  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.85123\tvalid_1's auc: 0.82969\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8297  \u001b[0m | \u001b[0m 0.3362  \u001b[0m | \u001b[0m 0.2874  \u001b[0m | \u001b[0m 0.005681\u001b[0m | \u001b[0m 136.5   \u001b[0m | \u001b[0m 6.849   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 9.101   \u001b[0m | \u001b[0m 0.9395  \u001b[0m | \u001b[0m 0.8948  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.739022\tvalid_1's auc: 0.728704\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7287  \u001b[0m | \u001b[0m 0.3815  \u001b[0m | \u001b[0m 0.8305  \u001b[0m | \u001b[0m 0.001796\u001b[0m | \u001b[0m 87.44   \u001b[0m | \u001b[0m 5.452   \u001b[0m | \u001b[0m 16.39   \u001b[0m | \u001b[0m 7.555   \u001b[0m | \u001b[0m 0.2713  \u001b[0m | \u001b[0m 0.8287  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.783443\tvalid_1's auc: 0.776797\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7768  \u001b[0m | \u001b[0m 0.5503  \u001b[0m | \u001b[0m 0.26    \u001b[0m | \u001b[0m 0.005884\u001b[0m | \u001b[0m 79.73   \u001b[0m | \u001b[0m 13.02   \u001b[0m | \u001b[0m 7.609   \u001b[0m | \u001b[0m 9.948   \u001b[0m | \u001b[0m 0.7722  \u001b[0m | \u001b[0m 0.1987  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.740033\tvalid_1's auc: 0.731143\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7311  \u001b[0m | \u001b[0m 0.7961  \u001b[0m | \u001b[0m 0.7358  \u001b[0m | \u001b[0m 0.007362\u001b[0m | \u001b[0m 162.1   \u001b[0m | \u001b[0m 12.71   \u001b[0m | \u001b[0m 7.592   \u001b[0m | \u001b[0m 7.434   \u001b[0m | \u001b[0m 0.1159  \u001b[0m | \u001b[0m 0.8631  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.83017\tvalid_1's auc: 0.811392\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8114  \u001b[0m | \u001b[0m 0.3637  \u001b[0m | \u001b[0m 0.3045  \u001b[0m | \u001b[0m 0.001572\u001b[0m | \u001b[0m 103.5   \u001b[0m | \u001b[0m 8.252   \u001b[0m | \u001b[0m 30.54   \u001b[0m | \u001b[0m 8.55    \u001b[0m | \u001b[0m 0.8872  \u001b[0m | \u001b[0m 0.4722  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.790981\tvalid_1's auc: 0.774274\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7743  \u001b[0m | \u001b[0m 0.7163  \u001b[0m | \u001b[0m 0.6448  \u001b[0m | \u001b[0m 0.007847\u001b[0m | \u001b[0m 138.6   \u001b[0m | \u001b[0m 12.71   \u001b[0m | \u001b[0m 22.28   \u001b[0m | \u001b[0m 8.091   \u001b[0m | \u001b[0m 0.4275  \u001b[0m | \u001b[0m 0.02542 \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.897291\tvalid_1's auc: 0.85599\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.856   \u001b[0m | \u001b[95m 0.7245  \u001b[0m | \u001b[95m 0.03797 \u001b[0m | \u001b[95m 0.006728\u001b[0m | \u001b[95m 104.0   \u001b[0m | \u001b[95m 10.09   \u001b[0m | \u001b[95m 36.76   \u001b[0m | \u001b[95m 6.997   \u001b[0m | \u001b[95m 0.4104  \u001b[0m | \u001b[95m 0.7556  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.881747\tvalid_1's auc: 0.853166\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8532  \u001b[0m | \u001b[0m 0.6398  \u001b[0m | \u001b[0m 0.07851 \u001b[0m | \u001b[0m 0.003608\u001b[0m | \u001b[0m 82.57   \u001b[0m | \u001b[0m 14.3    \u001b[0m | \u001b[0m 33.28   \u001b[0m | \u001b[0m 8.534   \u001b[0m | \u001b[0m 0.8715  \u001b[0m | \u001b[0m 0.8037  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.756966\tvalid_1's auc: 0.743828\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7438  \u001b[0m | \u001b[0m 0.6694  \u001b[0m | \u001b[0m 0.8044  \u001b[0m | \u001b[0m 0.005854\u001b[0m | \u001b[0m 173.0   \u001b[0m | \u001b[0m 13.96   \u001b[0m | \u001b[0m 16.13   \u001b[0m | \u001b[0m 6.44    \u001b[0m | \u001b[0m 0.2279  \u001b[0m | \u001b[0m 0.4271  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[88]\ttraining's auc: 0.737832\tvalid_1's auc: 0.730008\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.73    \u001b[0m | \u001b[0m 0.2274  \u001b[0m | \u001b[0m 0.7761  \u001b[0m | \u001b[0m 0.001063\u001b[0m | \u001b[0m 131.5   \u001b[0m | \u001b[0m 9.174   \u001b[0m | \u001b[0m 12.77   \u001b[0m | \u001b[0m 6.479   \u001b[0m | \u001b[0m 0.3376  \u001b[0m | \u001b[0m 0.9429  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.835425\tvalid_1's auc: 0.809747\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8097  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.3509  \u001b[0m | \u001b[0m 0.006417\u001b[0m | \u001b[0m 60.07   \u001b[0m | \u001b[0m 7.361   \u001b[0m | \u001b[0m 39.61   \u001b[0m | \u001b[0m 6.449   \u001b[0m | \u001b[0m 0.07893 \u001b[0m | \u001b[0m 0.4932  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.727742\tvalid_1's auc: 0.721539\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7215  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.4105  \u001b[0m | \u001b[0m 0.003865\u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 6.384   \u001b[0m | \u001b[0m 5.887   \u001b[0m | \u001b[0m 9.946   \u001b[0m | \u001b[0m 0.6954  \u001b[0m | \u001b[0m 0.7848  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.754985\tvalid_1's auc: 0.748632\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7486  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.3011  \u001b[0m | \u001b[0m 0.006179\u001b[0m | \u001b[0m 60.02   \u001b[0m | \u001b[0m 14.49   \u001b[0m | \u001b[0m 5.584   \u001b[0m | \u001b[0m 6.419   \u001b[0m | \u001b[0m 0.3764  \u001b[0m | \u001b[0m 0.02202 \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.876856\tvalid_1's auc: 0.847165\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.8472  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1239  \u001b[0m | \u001b[0m 0.00132 \u001b[0m | \u001b[0m 199.5   \u001b[0m | \u001b[0m 5.442   \u001b[0m | \u001b[0m 39.81   \u001b[0m | \u001b[0m 9.465   \u001b[0m | \u001b[0m 0.4562  \u001b[0m | \u001b[0m 0.1286  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.855847\tvalid_1's auc: 0.830787\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8308  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.2148  \u001b[0m | \u001b[0m 0.005497\u001b[0m | \u001b[0m 174.6   \u001b[0m | \u001b[0m 5.072   \u001b[0m | \u001b[0m 38.53   \u001b[0m | \u001b[0m 6.219   \u001b[0m | \u001b[0m 0.2524  \u001b[0m | \u001b[0m 0.131   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.806237\tvalid_1's auc: 0.785077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7851  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.4583  \u001b[0m | \u001b[0m 0.002687\u001b[0m | \u001b[0m 120.8   \u001b[0m | \u001b[0m 14.96   \u001b[0m | \u001b[0m 37.07   \u001b[0m | \u001b[0m 6.128   \u001b[0m | \u001b[0m 0.5338  \u001b[0m | \u001b[0m 0.008403\u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.834664\tvalid_1's auc: 0.810807\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8108  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.3084  \u001b[0m | \u001b[0m 0.002069\u001b[0m | \u001b[0m 81.52   \u001b[0m | \u001b[0m 5.304   \u001b[0m | \u001b[0m 39.94   \u001b[0m | \u001b[0m 9.665   \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.3836  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.884804\tvalid_1's auc: 0.854816\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.8548  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.04967 \u001b[0m | \u001b[0m 0.009168\u001b[0m | \u001b[0m 166.7   \u001b[0m | \u001b[0m 5.228   \u001b[0m | \u001b[0m 24.78   \u001b[0m | \u001b[0m 9.694   \u001b[0m | \u001b[0m 0.0646  \u001b[0m | \u001b[0m 0.3557  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.881874\tvalid_1's auc: 0.847946\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8479  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.02821 \u001b[0m | \u001b[0m 0.004251\u001b[0m | \u001b[0m 65.13   \u001b[0m | \u001b[0m 14.92   \u001b[0m | \u001b[0m 26.22   \u001b[0m | \u001b[0m 9.945   \u001b[0m | \u001b[0m 0.5897  \u001b[0m | \u001b[0m 0.9033  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.816384\tvalid_1's auc: 0.795554\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7956  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.4478  \u001b[0m | \u001b[0m 0.008542\u001b[0m | \u001b[0m 199.4   \u001b[0m | \u001b[0m 5.087   \u001b[0m | \u001b[0m 28.96   \u001b[0m | \u001b[0m 6.166   \u001b[0m | \u001b[0m 0.1602  \u001b[0m | \u001b[0m 0.5786  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.897254\tvalid_1's auc: 0.849628\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8496  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.03708 \u001b[0m | \u001b[0m 0.005694\u001b[0m | \u001b[0m 113.4   \u001b[0m | \u001b[0m 5.042   \u001b[0m | \u001b[0m 38.7    \u001b[0m | \u001b[0m 6.589   \u001b[0m | \u001b[0m 0.3567  \u001b[0m | \u001b[0m 0.1136  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.817167\tvalid_1's auc: 0.789091\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7891  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.6565  \u001b[0m | \u001b[0m 0.008688\u001b[0m | \u001b[0m 72.56   \u001b[0m | \u001b[0m 14.5    \u001b[0m | \u001b[0m 39.93   \u001b[0m | \u001b[0m 6.05    \u001b[0m | \u001b[0m 0.1463  \u001b[0m | \u001b[0m 0.3144  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's auc: 0.869319\tvalid_1's auc: 0.842935\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.8429  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.02303 \u001b[0m | \u001b[0m 0.009985\u001b[0m | \u001b[0m 60.04   \u001b[0m | \u001b[0m 5.506   \u001b[0m | \u001b[0m 15.65   \u001b[0m | \u001b[0m 9.69    \u001b[0m | \u001b[0m 0.66    \u001b[0m | \u001b[0m 0.6922  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.870451\tvalid_1's auc: 0.842642\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.8426  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1604  \u001b[0m | \u001b[0m 0.001925\u001b[0m | \u001b[0m 199.4   \u001b[0m | \u001b[0m 14.9    \u001b[0m | \u001b[0m 39.65   \u001b[0m | \u001b[0m 6.114   \u001b[0m | \u001b[0m 0.6128  \u001b[0m | \u001b[0m 0.9108  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.84611\tvalid_1's auc: 0.825035\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.825   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.2082  \u001b[0m | \u001b[0m 0.003259\u001b[0m | \u001b[0m 142.5   \u001b[0m | \u001b[0m 5.114   \u001b[0m | \u001b[0m 32.47   \u001b[0m | \u001b[0m 6.137   \u001b[0m | \u001b[0m 0.2249  \u001b[0m | \u001b[0m 0.5054  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.875348\tvalid_1's auc: 0.845935\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.8459  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1516  \u001b[0m | \u001b[0m 0.007849\u001b[0m | \u001b[0m 184.8   \u001b[0m | \u001b[0m 14.25   \u001b[0m | \u001b[0m 39.42   \u001b[0m | \u001b[0m 9.601   \u001b[0m | \u001b[0m 0.9867  \u001b[0m | \u001b[0m 0.3944  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.863924\tvalid_1's auc: 0.840952\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.841   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1592  \u001b[0m | \u001b[0m 0.005765\u001b[0m | \u001b[0m 185.7   \u001b[0m | \u001b[0m 5.163   \u001b[0m | \u001b[0m 30.53   \u001b[0m | \u001b[0m 9.612   \u001b[0m | \u001b[0m 0.598   \u001b[0m | \u001b[0m 0.91    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.858459\tvalid_1's auc: 0.83241\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.8324  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.2124  \u001b[0m | \u001b[0m 0.006824\u001b[0m | \u001b[0m 96.98   \u001b[0m | \u001b[0m 14.82   \u001b[0m | \u001b[0m 39.43   \u001b[0m | \u001b[0m 9.744   \u001b[0m | \u001b[0m 0.5619  \u001b[0m | \u001b[0m 0.1329  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.873268\tvalid_1's auc: 0.848135\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8481  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.09509 \u001b[0m | \u001b[0m 0.005022\u001b[0m | \u001b[0m 63.97   \u001b[0m | \u001b[0m 5.506   \u001b[0m | \u001b[0m 26.56   \u001b[0m | \u001b[0m 6.157   \u001b[0m | \u001b[0m 0.9475  \u001b[0m | \u001b[0m 0.8912  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.834492\tvalid_1's auc: 0.814095\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.8141  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.306   \u001b[0m | \u001b[0m 0.007959\u001b[0m | \u001b[0m 125.4   \u001b[0m | \u001b[0m 5.007   \u001b[0m | \u001b[0m 30.82   \u001b[0m | \u001b[0m 9.811   \u001b[0m | \u001b[0m 0.1617  \u001b[0m | \u001b[0m 0.9743  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.860941\tvalid_1's auc: 0.834287\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.8343  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.2204  \u001b[0m | \u001b[0m 0.009254\u001b[0m | \u001b[0m 156.5   \u001b[0m | \u001b[0m 5.315   \u001b[0m | \u001b[0m 39.95   \u001b[0m | \u001b[0m 9.875   \u001b[0m | \u001b[0m 0.5646  \u001b[0m | \u001b[0m 0.1744  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.723404\tvalid_1's auc: 0.718373\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7184  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.3943  \u001b[0m | \u001b[0m 0.004301\u001b[0m | \u001b[0m 172.0   \u001b[0m | \u001b[0m 5.008   \u001b[0m | \u001b[0m 5.491   \u001b[0m | \u001b[0m 9.855   \u001b[0m | \u001b[0m 0.4491  \u001b[0m | \u001b[0m 0.02218 \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.861052\tvalid_1's auc: 0.807535\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.8075  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.01177 \u001b[0m | \u001b[0m 0.008852\u001b[0m | \u001b[0m 155.1   \u001b[0m | \u001b[0m 6.096   \u001b[0m | \u001b[0m 23.84   \u001b[0m | \u001b[0m 6.705   \u001b[0m | \u001b[0m 0.9042  \u001b[0m | \u001b[0m 0.9034  \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.886216\tvalid_1's auc: 0.837066\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.8371  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.01755 \u001b[0m | \u001b[0m 0.00392 \u001b[0m | \u001b[0m 90.69   \u001b[0m | \u001b[0m 14.79   \u001b[0m | \u001b[0m 30.39   \u001b[0m | \u001b[0m 6.024   \u001b[0m | \u001b[0m 0.4889  \u001b[0m | \u001b[0m 0.04621 \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[90]\ttraining's auc: 0.817587\tvalid_1's auc: 0.809256\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.8093  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1212  \u001b[0m | \u001b[0m 0.005014\u001b[0m | \u001b[0m 198.5   \u001b[0m | \u001b[0m 14.92   \u001b[0m | \u001b[0m 6.776   \u001b[0m | \u001b[0m 6.088   \u001b[0m | \u001b[0m 0.5839  \u001b[0m | \u001b[0m 0.8784  \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=6, n_estimators=10000, output_process=False):\n",
    "    # prepare data\n",
    "#     Xtr, Xval, ytr, yval  = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "#     train_data = lgb.Dataset(data=Xtr, label=ytr, free_raw_data=False)\n",
    "#     val_data = lgb.Dataset(data=Xval, label=yval, free_raw_data=False)\n",
    "\n",
    "    # parameters\n",
    "    def lgb_eval(num_leaves, feature_fraction, bagging_fraction, learning_rate, num_threads, min_data_in_leaf, min_sum_hessian_in_leaf, reg_alpha, reg_lambda):\n",
    "        # fixed parameters\n",
    "        params = {'application':'binary',\n",
    "                  'num_iterations': n_estimators,\n",
    "                  'learning_rate':learning_rate,\n",
    "                  'early_stopping_round':100,\n",
    "                  'metric':'auc',\n",
    "                  'max_depth':-1,\n",
    "                  'bagging_freq':7,\n",
    "                  'verbosity':-1}\n",
    "        # variables\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['learning_rate'] = learning_rate\n",
    "        params['num_threads'] = int(num_threads)\n",
    "        params['min_data_in_leaf'] = int(min_data_in_leaf)\n",
    "        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n",
    "        params['reg_alpha'] = max(min(reg_alpha, 1), 0)\n",
    "        params['reg_lambda'] = max(min(reg_lambda, 1), 0)\n",
    "        \n",
    "        score = lgb_trainer_for_bayesian_optim(X, y, params)\n",
    "#         cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        \n",
    "        return score\n",
    "    # range of variables\n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (5, 40),\n",
    "                                            'feature_fraction': (0.01, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 0.1),\n",
    "                                            'learning_rate': (0.001, 0.01),\n",
    "                                            'num_threads': (6, 10),\n",
    "                                            'min_data_in_leaf': (60, 200),\n",
    "                                            'min_sum_hessian_in_leaf': (5.0 , 15.0),\n",
    "                                            'reg_alpha': (0.0 , 1.0),\n",
    "                                            'reg_lambda': (0.0 , 1.0),\n",
    "                                           },\n",
    "                                             random_state=42)\n",
    "    # optimize!\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbBO.res\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=42, n_estimators=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.855989966347573,\n",
       " 'params': {'bagging_fraction': 0.7244760011046869,\n",
       "  'feature_fraction': 0.03797197526119348,\n",
       "  'learning_rate': 0.006727693701374024,\n",
       "  'min_data_in_leaf': 104.00983735068573,\n",
       "  'min_sum_hessian_in_leaf': 10.085706911647028,\n",
       "  'num_leaves': 36.76482658741325,\n",
       "  'num_threads': 6.9971689165955,\n",
       "  'reg_alpha': 0.41038292303562973,\n",
       "  'reg_lambda': 0.7555511385430487}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bayesian search method #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | learni... | min_da... | min_su... | num_le... | num_th... | reg_alpha | reg_la... |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f57dc30c2940c0b8c87ddc1b870a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.767201\tvalid_1's auc: 0.751954\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.766277\tvalid_1's auc: 0.752167\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.759154\tvalid_1's auc: 0.745013\n",
      "\n",
      "Fold: 0 \t Score: 0.7518408137794815\n",
      "Fold: 1 \t Score: 0.7542204628041014\n",
      "Fold: 2 \t Score: 0.7472713187665752\n",
      "Score: 0.7562639845811869\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7563  \u001b[0m | \u001b[0m 0.5378  \u001b[0m | \u001b[0m 0.8561  \u001b[0m | \u001b[0m 0.007588\u001b[0m | \u001b[0m 143.8   \u001b[0m | \u001b[0m 6.56    \u001b[0m | \u001b[0m 10.46   \u001b[0m | \u001b[0m 6.232   \u001b[0m | \u001b[0m 0.8662  \u001b[0m | \u001b[0m 0.6011  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e16055ef7f43f384b46243aed99b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.859415\tvalid_1's auc: 0.835373\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.860071\tvalid_1's auc: 0.838353\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.859816\tvalid_1's auc: 0.837847\n",
      "\n",
      "Fold: 0 \t Score: 0.8361230835469673\n",
      "Fold: 1 \t Score: 0.8390002185736388\n",
      "Fold: 2 \t Score: 0.835786477016004\n",
      "Score: 0.8469717421492404\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.847   \u001b[0m | \u001b[95m 0.3043  \u001b[0m | \u001b[95m 0.02832 \u001b[0m | \u001b[95m 0.009729\u001b[0m | \u001b[95m 176.5   \u001b[0m | \u001b[95m 7.123   \u001b[0m | \u001b[95m 11.36   \u001b[0m | \u001b[95m 6.734   \u001b[0m | \u001b[95m 0.3042  \u001b[0m | \u001b[95m 0.5248  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977603d2d1474b76bb7632d1c670fc3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.828133\tvalid_1's auc: 0.80709\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.82801\tvalid_1's auc: 0.805623\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.826439\tvalid_1's auc: 0.802504\n",
      "\n",
      "Fold: 0 \t Score: 0.8066997038660655\n",
      "Fold: 1 \t Score: 0.8102106419399202\n",
      "Fold: 2 \t Score: 0.8070895006601568\n",
      "Score: 0.813737984423914\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.8137  \u001b[0m | \u001b[0m 0.4976  \u001b[0m | \u001b[0m 0.2692  \u001b[0m | \u001b[0m 0.006507\u001b[0m | \u001b[0m 79.53   \u001b[0m | \u001b[0m 7.921   \u001b[0m | \u001b[0m 17.82   \u001b[0m | \u001b[0m 7.824   \u001b[0m | \u001b[0m 0.7852  \u001b[0m | \u001b[0m 0.1997  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e42983e11924de5976947b237590e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[92]\ttraining's auc: 0.736838\tvalid_1's auc: 0.726811\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[94]\ttraining's auc: 0.733559\tvalid_1's auc: 0.725261\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[93]\ttraining's auc: 0.726603\tvalid_1's auc: 0.714184\n",
      "\n",
      "Fold: 0 \t Score: 0.7272947820358671\n",
      "Fold: 1 \t Score: 0.7250038684291252\n",
      "Fold: 2 \t Score: 0.7171327088431144\n",
      "Score: 0.7278905177417435\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7279  \u001b[0m | \u001b[0m 0.44    \u001b[0m | \u001b[0m 0.5372  \u001b[0m | \u001b[0m 0.001418\u001b[0m | \u001b[0m 145.1   \u001b[0m | \u001b[0m 6.705   \u001b[0m | \u001b[0m 7.277   \u001b[0m | \u001b[0m 9.796   \u001b[0m | \u001b[0m 0.9656  \u001b[0m | \u001b[0m 0.8084  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc8a8affa2c41329129a4ff1c10bf65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.875012\tvalid_1's auc: 0.845555\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.876435\tvalid_1's auc: 0.846544\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.873744\tvalid_1's auc: 0.846113\n",
      "\n",
      "Fold: 0 \t Score: 0.8455542257158866\n",
      "Fold: 1 \t Score: 0.8470968113300645\n",
      "Fold: 2 \t Score: 0.8449288526183807\n",
      "Score: 0.851553623749496\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.8516  \u001b[0m | \u001b[95m 0.5868  \u001b[0m | \u001b[95m 0.09693 \u001b[0m | \u001b[95m 0.007158\u001b[0m | \u001b[95m 121.6   \u001b[0m | \u001b[95m 6.22    \u001b[0m | \u001b[95m 22.33   \u001b[0m | \u001b[95m 6.138   \u001b[0m | \u001b[95m 0.9093  \u001b[0m | \u001b[95m 0.2588  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1480ada68a40538e4f02d9006bede7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.864277\tvalid_1's auc: 0.830546\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's auc: 0.865446\tvalid_1's auc: 0.829247\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.862701\tvalid_1's auc: 0.826078\n",
      "\n",
      "Fold: 0 \t Score: 0.8311234231583674\n",
      "Fold: 1 \t Score: 0.8308484368402098\n",
      "Fold: 2 \t Score: 0.828943465365086\n",
      "Score: 0.8369460641826049\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8369  \u001b[0m | \u001b[0m 0.3362  \u001b[0m | \u001b[0m 0.2874  \u001b[0m | \u001b[0m 0.005681\u001b[0m | \u001b[0m 136.5   \u001b[0m | \u001b[0m 6.849   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 9.101   \u001b[0m | \u001b[0m 0.9395  \u001b[0m | \u001b[0m 0.8948  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729ef5cce5ba4f9eb6cfa812c7081810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.74505\tvalid_1's auc: 0.731012\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[93]\ttraining's auc: 0.746272\tvalid_1's auc: 0.733955\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.743898\tvalid_1's auc: 0.7277\n",
      "\n",
      "Fold: 0 \t Score: 0.7293581311905616\n",
      "Fold: 1 \t Score: 0.7332090987628498\n",
      "Fold: 2 \t Score: 0.7318917899571168\n",
      "Score: 0.7370946597213762\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7371  \u001b[0m | \u001b[0m 0.3815  \u001b[0m | \u001b[0m 0.8305  \u001b[0m | \u001b[0m 0.001796\u001b[0m | \u001b[0m 87.44   \u001b[0m | \u001b[0m 5.452   \u001b[0m | \u001b[0m 16.39   \u001b[0m | \u001b[0m 7.555   \u001b[0m | \u001b[0m 0.2713  \u001b[0m | \u001b[0m 0.8287  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba49444965894384863fe1902d9193b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.789438\tvalid_1's auc: 0.777064\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.790367\tvalid_1's auc: 0.77603\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.785702\tvalid_1's auc: 0.77\n",
      "\n",
      "Fold: 0 \t Score: 0.7779648675184799\n",
      "Fold: 1 \t Score: 0.7793539804600972\n",
      "Fold: 2 \t Score: 0.7746802124083543\n",
      "Score: 0.78285206965904\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7829  \u001b[0m | \u001b[0m 0.5503  \u001b[0m | \u001b[0m 0.26    \u001b[0m | \u001b[0m 0.005884\u001b[0m | \u001b[0m 79.73   \u001b[0m | \u001b[0m 13.02   \u001b[0m | \u001b[0m 7.609   \u001b[0m | \u001b[0m 9.948   \u001b[0m | \u001b[0m 0.7722  \u001b[0m | \u001b[0m 0.1987  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9919bf10af04940bebff5d0f6fe9a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.744424\tvalid_1's auc: 0.730922\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.746247\tvalid_1's auc: 0.735853\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.741689\tvalid_1's auc: 0.72648\n",
      "\n",
      "Fold: 0 \t Score: 0.7310623270980781\n",
      "Fold: 1 \t Score: 0.735950110497265\n",
      "Fold: 2 \t Score: 0.7306694336571493\n",
      "Score: 0.7370721843877998\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7371  \u001b[0m | \u001b[0m 0.7961  \u001b[0m | \u001b[0m 0.7358  \u001b[0m | \u001b[0m 0.007362\u001b[0m | \u001b[0m 162.1   \u001b[0m | \u001b[0m 12.71   \u001b[0m | \u001b[0m 7.592   \u001b[0m | \u001b[0m 7.434   \u001b[0m | \u001b[0m 0.1159  \u001b[0m | \u001b[0m 0.8631  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84466e6ae8f9421d850ad8234560e29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.843614\tvalid_1's auc: 0.814029\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.84248\tvalid_1's auc: 0.81172\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.84051\tvalid_1's auc: 0.810284\n",
      "\n",
      "Fold: 0 \t Score: 0.8154275978781571\n",
      "Fold: 1 \t Score: 0.8165131238578311\n",
      "Fold: 2 \t Score: 0.8128612288673485\n",
      "Score: 0.821784867670627\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.8218  \u001b[0m | \u001b[0m 0.3637  \u001b[0m | \u001b[0m 0.3045  \u001b[0m | \u001b[0m 0.001572\u001b[0m | \u001b[0m 103.5   \u001b[0m | \u001b[0m 8.252   \u001b[0m | \u001b[0m 30.54   \u001b[0m | \u001b[0m 8.55    \u001b[0m | \u001b[0m 0.8872  \u001b[0m | \u001b[0m 0.4722  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04be0e23ab7e4569b3bc155417428704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.803071\tvalid_1's auc: 0.776778\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.802533\tvalid_1's auc: 0.775257\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.798879\tvalid_1's auc: 0.770968\n",
      "\n",
      "Fold: 0 \t Score: 0.776373323611879\n",
      "Fold: 1 \t Score: 0.7783825579283198\n",
      "Fold: 2 \t Score: 0.7740885455128668\n",
      "Score: 0.7823998980356797\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7824  \u001b[0m | \u001b[0m 0.7163  \u001b[0m | \u001b[0m 0.6448  \u001b[0m | \u001b[0m 0.007847\u001b[0m | \u001b[0m 138.6   \u001b[0m | \u001b[0m 12.71   \u001b[0m | \u001b[0m 22.28   \u001b[0m | \u001b[0m 8.091   \u001b[0m | \u001b[0m 0.4275  \u001b[0m | \u001b[0m 0.02542 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab63e5eaa5d46288eaf9197f025cdb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.908426\tvalid_1's auc: 0.851058\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.910643\tvalid_1's auc: 0.852085\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.908561\tvalid_1's auc: 0.854317\n",
      "\n",
      "Fold: 0 \t Score: 0.8517033505331273\n",
      "Fold: 1 \t Score: 0.8535507672066608\n",
      "Fold: 2 \t Score: 0.8513917619173366\n",
      "Score: 0.8613145741028642\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.8613  \u001b[0m | \u001b[95m 0.7245  \u001b[0m | \u001b[95m 0.03797 \u001b[0m | \u001b[95m 0.006728\u001b[0m | \u001b[95m 104.0   \u001b[0m | \u001b[95m 10.09   \u001b[0m | \u001b[95m 36.76   \u001b[0m | \u001b[95m 6.997   \u001b[0m | \u001b[95m 0.4104  \u001b[0m | \u001b[95m 0.7556  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b961ccea83d431590bb9fae8d15337a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.891066\tvalid_1's auc: 0.852953\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.893847\tvalid_1's auc: 0.85316\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.892568\tvalid_1's auc: 0.853593\n",
      "\n",
      "Fold: 0 \t Score: 0.8505809231285738\n",
      "Fold: 1 \t Score: 0.8530690295743097\n",
      "Fold: 2 \t Score: 0.8532468403273917\n",
      "Score: 0.8588486846535369\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.8588  \u001b[0m | \u001b[0m 0.6398  \u001b[0m | \u001b[0m 0.07851 \u001b[0m | \u001b[0m 0.003608\u001b[0m | \u001b[0m 82.57   \u001b[0m | \u001b[0m 14.3    \u001b[0m | \u001b[0m 33.28   \u001b[0m | \u001b[0m 8.534   \u001b[0m | \u001b[0m 0.8715  \u001b[0m | \u001b[0m 0.8037  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36315941a184150b7018fd1cb4f47d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.77165\tvalid_1's auc: 0.751545\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.769864\tvalid_1's auc: 0.750892\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.764045\tvalid_1's auc: 0.743914\n",
      "\n",
      "Fold: 0 \t Score: 0.7507895990546655\n",
      "Fold: 1 \t Score: 0.7529023687893458\n",
      "Fold: 2 \t Score: 0.747354285787436\n",
      "Score: 0.756070867350928\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7561  \u001b[0m | \u001b[0m 0.6694  \u001b[0m | \u001b[0m 0.8044  \u001b[0m | \u001b[0m 0.005854\u001b[0m | \u001b[0m 173.0   \u001b[0m | \u001b[0m 13.96   \u001b[0m | \u001b[0m 16.13   \u001b[0m | \u001b[0m 6.44    \u001b[0m | \u001b[0m 0.2279  \u001b[0m | \u001b[0m 0.4271  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b912829f071f41ee8238457eb14e35bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.753628\tvalid_1's auc: 0.741169\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.752455\tvalid_1's auc: 0.740059\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.749255\tvalid_1's auc: 0.73618\n",
      "\n",
      "Fold: 0 \t Score: 0.7425848174118109\n",
      "Fold: 1 \t Score: 0.7422146780366656\n",
      "Fold: 2 \t Score: 0.7382300923628116\n",
      "Score: 0.7479140208493457\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7479  \u001b[0m | \u001b[0m 0.2274  \u001b[0m | \u001b[0m 0.7761  \u001b[0m | \u001b[0m 0.001063\u001b[0m | \u001b[0m 131.5   \u001b[0m | \u001b[0m 9.174   \u001b[0m | \u001b[0m 12.77   \u001b[0m | \u001b[0m 6.479   \u001b[0m | \u001b[0m 0.3376  \u001b[0m | \u001b[0m 0.9429  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7205711423574aa1aa5e46039a3ef18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.848534\tvalid_1's auc: 0.810554\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.847757\tvalid_1's auc: 0.807442\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.845803\tvalid_1's auc: 0.805744\n",
      "\n",
      "Fold: 0 \t Score: 0.8102521186520041\n",
      "Fold: 1 \t Score: 0.8120966256332294\n",
      "Fold: 2 \t Score: 0.8091804137107937\n",
      "Score: 0.8166036846317484\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.8166  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.3509  \u001b[0m | \u001b[0m 0.006417\u001b[0m | \u001b[0m 60.07   \u001b[0m | \u001b[0m 7.361   \u001b[0m | \u001b[0m 39.61   \u001b[0m | \u001b[0m 6.449   \u001b[0m | \u001b[0m 0.07893 \u001b[0m | \u001b[0m 0.4932  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6364233490cf4150a08a4b4297909f1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.736286\tvalid_1's auc: 0.726649\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.734431\tvalid_1's auc: 0.726839\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.729499\tvalid_1's auc: 0.716876\n",
      "\n",
      "Fold: 0 \t Score: 0.7256430455692283\n",
      "Fold: 1 \t Score: 0.7275648871412274\n",
      "Fold: 2 \t Score: 0.7210373153694006\n",
      "Score: 0.7286261634188846\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7286  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.4105  \u001b[0m | \u001b[0m 0.003865\u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 6.384   \u001b[0m | \u001b[0m 5.887   \u001b[0m | \u001b[0m 9.946   \u001b[0m | \u001b[0m 0.6954  \u001b[0m | \u001b[0m 0.7848  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6223504df54c7bb11cdeddc2e26178",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.857882\tvalid_1's auc: 0.821949\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.856438\tvalid_1's auc: 0.816875\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.856483\tvalid_1's auc: 0.817984\n",
      "\n",
      "Fold: 0 \t Score: 0.8214465887464211\n",
      "Fold: 1 \t Score: 0.8217456412112394\n",
      "Fold: 2 \t Score: 0.8194101508464033\n",
      "Score: 0.8267193455128476\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.2854  \u001b[0m | \u001b[0m 0.006009\u001b[0m | \u001b[0m 199.5   \u001b[0m | \u001b[0m 5.22    \u001b[0m | \u001b[0m 39.55   \u001b[0m | \u001b[0m 8.097   \u001b[0m | \u001b[0m 0.8658  \u001b[0m | \u001b[0m 0.8095  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba64fb0fdd04873a1226a2866ec9502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.739758\tvalid_1's auc: 0.727279\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.742174\tvalid_1's auc: 0.732617\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.735594\tvalid_1's auc: 0.724546\n",
      "\n",
      "Fold: 0 \t Score: 0.7278187713918046\n",
      "Fold: 1 \t Score: 0.7338886444845548\n",
      "Fold: 2 \t Score: 0.7281166001542505\n",
      "Score: 0.7346489103735976\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7346  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.4905  \u001b[0m | \u001b[0m 0.009602\u001b[0m | \u001b[0m 60.54   \u001b[0m | \u001b[0m 14.9    \u001b[0m | \u001b[0m 5.07    \u001b[0m | \u001b[0m 6.31    \u001b[0m | \u001b[0m 0.9158  \u001b[0m | \u001b[0m 0.8414  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c0ccf9deaf4dd78acae8c7c3149b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.867045\tvalid_1's auc: 0.831371\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.867676\tvalid_1's auc: 0.82855\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.864868\tvalid_1's auc: 0.825478\n",
      "\n",
      "Fold: 0 \t Score: 0.8301069207908536\n",
      "Fold: 1 \t Score: 0.8317870709467489\n",
      "Fold: 2 \t Score: 0.8267184821228402\n",
      "Score: 0.8356415974534374\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.8356  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.2148  \u001b[0m | \u001b[0m 0.005497\u001b[0m | \u001b[0m 174.6   \u001b[0m | \u001b[0m 5.072   \u001b[0m | \u001b[0m 38.53   \u001b[0m | \u001b[0m 6.219   \u001b[0m | \u001b[0m 0.2524  \u001b[0m | \u001b[0m 0.131   \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8469c4729a49a1a0f065da0ec899ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.856118\tvalid_1's auc: 0.821298\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.854788\tvalid_1's auc: 0.816738\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.85379\tvalid_1's auc: 0.814866\n",
      "\n",
      "Fold: 0 \t Score: 0.8204725080611563\n",
      "Fold: 1 \t Score: 0.8206203313077637\n",
      "Fold: 2 \t Score: 0.8183937232607011\n",
      "Score: 0.8262750803664834\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.8263  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.2522  \u001b[0m | \u001b[0m 0.001977\u001b[0m | \u001b[0m 118.4   \u001b[0m | \u001b[0m 14.11   \u001b[0m | \u001b[0m 39.94   \u001b[0m | \u001b[0m 6.666   \u001b[0m | \u001b[0m 0.867   \u001b[0m | \u001b[0m 0.1801  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80903ba51e3e4330b413d85547a8c57f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.846409\tvalid_1's auc: 0.810815\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.84581\tvalid_1's auc: 0.808109\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.845076\tvalid_1's auc: 0.807397\n",
      "\n",
      "Fold: 0 \t Score: 0.8102688969712013\n",
      "Fold: 1 \t Score: 0.81126629598501\n",
      "Fold: 2 \t Score: 0.8100772991713883\n",
      "Score: 0.816920242838841\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.8169  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.3084  \u001b[0m | \u001b[0m 0.002069\u001b[0m | \u001b[0m 81.52   \u001b[0m | \u001b[0m 5.304   \u001b[0m | \u001b[0m 39.94   \u001b[0m | \u001b[0m 9.665   \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.3836  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee69c2975474d6e9dde84ab613eb4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.829469\tvalid_1's auc: 0.801968\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.826822\tvalid_1's auc: 0.797062\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.825764\tvalid_1's auc: 0.79547\n",
      "\n",
      "Fold: 0 \t Score: 0.8017395486690602\n",
      "Fold: 1 \t Score: 0.8005332432652129\n",
      "Fold: 2 \t Score: 0.7992054582075013\n",
      "Score: 0.8060167963620091\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.806   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.3613  \u001b[0m | \u001b[0m 0.00773 \u001b[0m | \u001b[0m 61.42   \u001b[0m | \u001b[0m 14.88   \u001b[0m | \u001b[0m 26.42   \u001b[0m | \u001b[0m 9.988   \u001b[0m | \u001b[0m 0.09399 \u001b[0m | \u001b[0m 0.3815  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e5a8ceb253422ea268718385f1b530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.826754\tvalid_1's auc: 0.803176\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.825102\tvalid_1's auc: 0.799227\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.824431\tvalid_1's auc: 0.797413\n",
      "\n",
      "Fold: 0 \t Score: 0.8028262915527601\n",
      "Fold: 1 \t Score: 0.8043526223204224\n",
      "Fold: 2 \t Score: 0.8012828221535353\n",
      "Score: 0.8088965555504348\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.8089  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.2743  \u001b[0m | \u001b[0m 0.002667\u001b[0m | \u001b[0m 167.1   \u001b[0m | \u001b[0m 5.092   \u001b[0m | \u001b[0m 23.22   \u001b[0m | \u001b[0m 9.925   \u001b[0m | \u001b[0m 0.2172  \u001b[0m | \u001b[0m 0.4309  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce58335b8cd4d0d9a32e80e1136eac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.882017\tvalid_1's auc: 0.843385\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.885445\tvalid_1's auc: 0.846429\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.882821\tvalid_1's auc: 0.84267\n",
      "\n",
      "Fold: 0 \t Score: 0.8425543873329782\n",
      "Fold: 1 \t Score: 0.8457572855279226\n",
      "Fold: 2 \t Score: 0.8418890807480475\n",
      "Score: 0.8496149800640869\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.8496  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1276  \u001b[0m | \u001b[0m 0.001595\u001b[0m | \u001b[0m 123.2   \u001b[0m | \u001b[0m 5.006   \u001b[0m | \u001b[0m 37.4    \u001b[0m | \u001b[0m 6.082   \u001b[0m | \u001b[0m 0.08664 \u001b[0m | \u001b[0m 0.07625 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71936c7dfedf405aaa2812409b67799f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.872074\tvalid_1's auc: 0.834406\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's auc: 0.872222\tvalid_1's auc: 0.831941\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's auc: 0.870175\tvalid_1's auc: 0.828973\n",
      "\n",
      "Fold: 0 \t Score: 0.8332255534807531\n",
      "Fold: 1 \t Score: 0.8342227077540874\n",
      "Fold: 2 \t Score: 0.8308457107032576\n",
      "Score: 0.8386275400160703\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.8386  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.2132  \u001b[0m | \u001b[0m 0.009061\u001b[0m | \u001b[0m 70.3    \u001b[0m | \u001b[0m 13.69   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 6.287   \u001b[0m | \u001b[0m 0.5196  \u001b[0m | \u001b[0m 0.1065  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad245446267449d853fdbc6c37603c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.8836\tvalid_1's auc: 0.849689\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.884684\tvalid_1's auc: 0.849871\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.884636\tvalid_1's auc: 0.849704\n",
      "\n",
      "Fold: 0 \t Score: 0.8482005160883177\n",
      "Fold: 1 \t Score: 0.8492977828124217\n",
      "Fold: 2 \t Score: 0.8483372716267997\n",
      "Score: 0.8546310788545584\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.8546  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.07683 \u001b[0m | \u001b[0m 0.002046\u001b[0m | \u001b[0m 188.9   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 25.93   \u001b[0m | \u001b[0m 6.093   \u001b[0m | \u001b[0m 0.6619  \u001b[0m | \u001b[0m 0.1439  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f027e7cfc74441f91dd828ec4272e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.909881\tvalid_1's auc: 0.851392\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.912702\tvalid_1's auc: 0.853729\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.910828\tvalid_1's auc: 0.855954\n",
      "\n",
      "Fold: 0 \t Score: 0.8521514499469256\n",
      "Fold: 1 \t Score: 0.8550566417496616\n",
      "Fold: 2 \t Score: 0.8534180906760874\n",
      "Score: 0.8620098138074975\n",
      "| \u001b[95m 28      \u001b[0m | \u001b[95m 0.862   \u001b[0m | \u001b[95m 0.8     \u001b[0m | \u001b[95m 0.03958 \u001b[0m | \u001b[95m 0.007665\u001b[0m | \u001b[95m 98.92   \u001b[0m | \u001b[95m 14.91   \u001b[0m | \u001b[95m 37.89   \u001b[0m | \u001b[95m 6.376   \u001b[0m | \u001b[95m 0.6718  \u001b[0m | \u001b[95m 0.07763 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1047d6b83c4577a07ecc3c867edb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.879594\tvalid_1's auc: 0.840075\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.882364\tvalid_1's auc: 0.840709\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.880778\tvalid_1's auc: 0.840065\n",
      "\n",
      "Fold: 0 \t Score: 0.8392103486660498\n",
      "Fold: 1 \t Score: 0.84327215675796\n",
      "Fold: 2 \t Score: 0.8404846375350403\n",
      "Score: 0.8468754027807862\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.8469  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1604  \u001b[0m | \u001b[0m 0.001925\u001b[0m | \u001b[0m 199.4   \u001b[0m | \u001b[0m 14.9    \u001b[0m | \u001b[0m 39.65   \u001b[0m | \u001b[0m 6.114   \u001b[0m | \u001b[0m 0.6128  \u001b[0m | \u001b[0m 0.9108  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1db81583cad40fbb6fcf1f55c259eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.879372\tvalid_1's auc: 0.841874\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.880893\tvalid_1's auc: 0.841469\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.880082\tvalid_1's auc: 0.842285\n",
      "\n",
      "Fold: 0 \t Score: 0.8417849096844084\n",
      "Fold: 1 \t Score: 0.844693663820718\n",
      "Fold: 2 \t Score: 0.8429627300163609\n",
      "Score: 0.8489550441729024\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.849   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1608  \u001b[0m | \u001b[0m 0.008573\u001b[0m | \u001b[0m 149.1   \u001b[0m | \u001b[0m 5.788   \u001b[0m | \u001b[0m 33.93   \u001b[0m | \u001b[0m 6.039   \u001b[0m | \u001b[0m 0.8799  \u001b[0m | \u001b[0m 0.8948  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54823a3efee44d80b25e108c1938b760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.874002\tvalid_1's auc: 0.845148\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.875531\tvalid_1's auc: 0.845908\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.873142\tvalid_1's auc: 0.844577\n",
      "\n",
      "Fold: 0 \t Score: 0.8442080239374675\n",
      "Fold: 1 \t Score: 0.847331904950876\n",
      "Fold: 2 \t Score: 0.8434215436242656\n",
      "Score: 0.8508606139025193\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.8509  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1081  \u001b[0m | \u001b[0m 0.004235\u001b[0m | \u001b[0m 76.26   \u001b[0m | \u001b[0m 14.08   \u001b[0m | \u001b[0m 23.25   \u001b[0m | \u001b[0m 6.096   \u001b[0m | \u001b[0m 0.8059  \u001b[0m | \u001b[0m 0.9912  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88409ba816d3437b95932176ac773097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.795703\tvalid_1's auc: 0.787219\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[97]\ttraining's auc: 0.79657\tvalid_1's auc: 0.784644\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[96]\ttraining's auc: 0.796028\tvalid_1's auc: 0.782744\n",
      "\n",
      "Fold: 0 \t Score: 0.786032067623751\n",
      "Fold: 1 \t Score: 0.7884902545464775\n",
      "Fold: 2 \t Score: 0.7862113740130662\n",
      "Score: 0.7933833542526387\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7934  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1285  \u001b[0m | \u001b[0m 0.005385\u001b[0m | \u001b[0m 174.7   \u001b[0m | \u001b[0m 5.168   \u001b[0m | \u001b[0m 5.048   \u001b[0m | \u001b[0m 6.381   \u001b[0m | \u001b[0m 0.4469  \u001b[0m | \u001b[0m 0.09482 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4a093737e14587b414402d85964cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.872637\tvalid_1's auc: 0.845526\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[98]\ttraining's auc: 0.873368\tvalid_1's auc: 0.845794\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's auc: 0.873087\tvalid_1's auc: 0.845054\n",
      "\n",
      "Fold: 0 \t Score: 0.8442358155780182\n",
      "Fold: 1 \t Score: 0.8459347087752533\n",
      "Fold: 2 \t Score: 0.8437040557120148\n",
      "Score: 0.8502226842590017\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.8502  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.07611 \u001b[0m | \u001b[0m 0.002582\u001b[0m | \u001b[0m 200.0   \u001b[0m | \u001b[0m 13.91   \u001b[0m | \u001b[0m 19.11   \u001b[0m | \u001b[0m 6.449   \u001b[0m | \u001b[0m 0.07819 \u001b[0m | \u001b[0m 0.9942  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81844bc1bdc24f16a211c9663ce5f072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.862336\tvalid_1's auc: 0.83573\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.863252\tvalid_1's auc: 0.833124\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.861917\tvalid_1's auc: 0.832039\n",
      "\n",
      "Fold: 0 \t Score: 0.834645381351922\n",
      "Fold: 1 \t Score: 0.8366576443317348\n",
      "Fold: 2 \t Score: 0.8331192545346553\n",
      "Score: 0.840282447911358\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8403  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1504  \u001b[0m | \u001b[0m 0.004494\u001b[0m | \u001b[0m 193.1   \u001b[0m | \u001b[0m 11.59   \u001b[0m | \u001b[0m 23.5    \u001b[0m | \u001b[0m 9.995   \u001b[0m | \u001b[0m 0.8876  \u001b[0m | \u001b[0m 0.9995  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fb1fa771754e1a92048eb830a9c624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.88315\tvalid_1's auc: 0.846003\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.884582\tvalid_1's auc: 0.847517\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.88292\tvalid_1's auc: 0.847766\n",
      "\n",
      "Fold: 0 \t Score: 0.846391115768492\n",
      "Fold: 1 \t Score: 0.8491958416064396\n",
      "Fold: 2 \t Score: 0.8474076453293922\n",
      "Score: 0.8551640352295483\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.8552  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.03256 \u001b[0m | \u001b[0m 0.003214\u001b[0m | \u001b[0m 60.33   \u001b[0m | \u001b[0m 5.408   \u001b[0m | \u001b[0m 18.82   \u001b[0m | \u001b[0m 9.501   \u001b[0m | \u001b[0m 0.8828  \u001b[0m | \u001b[0m 0.9641  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99281b8546304a03b67c68dfe07fd088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[90]\ttraining's auc: 0.857083\tvalid_1's auc: 0.829144\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.857218\tvalid_1's auc: 0.825828\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.854504\tvalid_1's auc: 0.822396\n",
      "\n",
      "Fold: 0 \t Score: 0.8287660013276762\n",
      "Fold: 1 \t Score: 0.8295088702479889\n",
      "Fold: 2 \t Score: 0.8252034230136988\n",
      "Score: 0.8341483746332997\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.8341  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1791  \u001b[0m | \u001b[0m 0.003127\u001b[0m | \u001b[0m 133.2   \u001b[0m | \u001b[0m 5.559   \u001b[0m | \u001b[0m 27.74   \u001b[0m | \u001b[0m 6.286   \u001b[0m | \u001b[0m 0.5271  \u001b[0m | \u001b[0m 0.9724  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a55113550464453a77d8e7795ab6a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.90217\tvalid_1's auc: 0.854819\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.90463\tvalid_1's auc: 0.855848\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.903297\tvalid_1's auc: 0.857765\n",
      "\n",
      "Fold: 0 \t Score: 0.8540125856837252\n",
      "Fold: 1 \t Score: 0.857291190265453\n",
      "Fold: 2 \t Score: 0.8538080098404162\n",
      "Score: 0.8615894040590519\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.8616  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.08078 \u001b[0m | \u001b[0m 0.008005\u001b[0m | \u001b[0m 158.1   \u001b[0m | \u001b[0m 13.86   \u001b[0m | \u001b[0m 39.8    \u001b[0m | \u001b[0m 6.114   \u001b[0m | \u001b[0m 0.1391  \u001b[0m | \u001b[0m 0.6918  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4193d201b34cff805e2e72cd38f156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's auc: 0.885152\tvalid_1's auc: 0.845273\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.887682\tvalid_1's auc: 0.845392\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.885929\tvalid_1's auc: 0.843644\n",
      "\n",
      "Fold: 0 \t Score: 0.8439208209906237\n",
      "Fold: 1 \t Score: 0.8479599158068293\n",
      "Fold: 2 \t Score: 0.8430022148129159\n",
      "Score: 0.8508589551059698\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.8509  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1428  \u001b[0m | \u001b[0m 0.005284\u001b[0m | \u001b[0m 160.0   \u001b[0m | \u001b[0m 5.168   \u001b[0m | \u001b[0m 39.25   \u001b[0m | \u001b[0m 9.251   \u001b[0m | \u001b[0m 0.2923  \u001b[0m | \u001b[0m 0.7592  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba901710b3394c4b92e7b2e4b947d348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.867894\tvalid_1's auc: 0.839998\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.870967\tvalid_1's auc: 0.842324\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.867595\tvalid_1's auc: 0.840109\n",
      "\n",
      "Fold: 0 \t Score: 0.8400209223192985\n",
      "Fold: 1 \t Score: 0.8433031844114512\n",
      "Fold: 2 \t Score: 0.8392386433842425\n",
      "Score: 0.8465645687814582\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.8466  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.09536 \u001b[0m | \u001b[0m 0.001585\u001b[0m | \u001b[0m 199.5   \u001b[0m | \u001b[0m 5.402   \u001b[0m | \u001b[0m 20.51   \u001b[0m | \u001b[0m 6.842   \u001b[0m | \u001b[0m 0.5052  \u001b[0m | \u001b[0m 0.3261  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49e8265530e44d6977c12166ffc0fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.897639\tvalid_1's auc: 0.83985\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.899184\tvalid_1's auc: 0.845221\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.900126\tvalid_1's auc: 0.840007\n",
      "\n",
      "Fold: 0 \t Score: 0.8395472407275669\n",
      "Fold: 1 \t Score: 0.8431426754502482\n",
      "Fold: 2 \t Score: 0.8398102891492454\n",
      "Score: 0.8504788323589684\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.8505  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.02707 \u001b[0m | \u001b[0m 0.001732\u001b[0m | \u001b[0m 66.17   \u001b[0m | \u001b[0m 5.273   \u001b[0m | \u001b[0m 31.14   \u001b[0m | \u001b[0m 6.074   \u001b[0m | \u001b[0m 0.3935  \u001b[0m | \u001b[0m 0.01326 \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4c3c52bbd848c288263714f089b4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.906579\tvalid_1's auc: 0.838978\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.907094\tvalid_1's auc: 0.846567\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.907644\tvalid_1's auc: 0.842569\n",
      "\n",
      "Fold: 0 \t Score: 0.8424106974810515\n",
      "Fold: 1 \t Score: 0.8456626185527107\n",
      "Fold: 2 \t Score: 0.8435697679733173\n",
      "Score: 0.8540392895888334\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.854   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.0276  \u001b[0m | \u001b[0m 0.001014\u001b[0m | \u001b[0m 140.9   \u001b[0m | \u001b[0m 14.97   \u001b[0m | \u001b[0m 38.79   \u001b[0m | \u001b[0m 6.036   \u001b[0m | \u001b[0m 0.06013 \u001b[0m | \u001b[0m 0.2837  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14daf3a8bb824c5b8f4cf3caf6903ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.912985\tvalid_1's auc: 0.848954\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.914573\tvalid_1's auc: 0.84948\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.913367\tvalid_1's auc: 0.849147\n",
      "\n",
      "Fold: 0 \t Score: 0.8488953274971205\n",
      "Fold: 1 \t Score: 0.8501552650566193\n",
      "Fold: 2 \t Score: 0.8473361335224081\n",
      "Score: 0.8590718267811764\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.8591  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.03358 \u001b[0m | \u001b[0m 0.008724\u001b[0m | \u001b[0m 92.98   \u001b[0m | \u001b[0m 6.174   \u001b[0m | \u001b[0m 39.53   \u001b[0m | \u001b[0m 6.154   \u001b[0m | \u001b[0m 0.6205  \u001b[0m | \u001b[0m 0.4519  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e814e371bb4bc6a7b6d8bab41b6e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's auc: 0.872639\tvalid_1's auc: 0.844359\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's auc: 0.874867\tvalid_1's auc: 0.848127\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[99]\ttraining's auc: 0.872919\tvalid_1's auc: 0.847025\n",
      "\n",
      "Fold: 0 \t Score: 0.8445536518742555\n",
      "Fold: 1 \t Score: 0.8477309542945736\n",
      "Fold: 2 \t Score: 0.846467434006462\n",
      "Score: 0.8519582613340282\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.852   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.06408 \u001b[0m | \u001b[0m 0.003574\u001b[0m | \u001b[0m 186.7   \u001b[0m | \u001b[0m 5.475   \u001b[0m | \u001b[0m 17.24   \u001b[0m | \u001b[0m 6.375   \u001b[0m | \u001b[0m 0.1591  \u001b[0m | \u001b[0m 0.7789  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ff267b70a14987b27973158820a34e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.883623\tvalid_1's auc: 0.847497\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.885559\tvalid_1's auc: 0.848686\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.884389\tvalid_1's auc: 0.849432\n",
      "\n",
      "Fold: 0 \t Score: 0.847435348591438\n",
      "Fold: 1 \t Score: 0.8499192128689491\n",
      "Fold: 2 \t Score: 0.8481593249067875\n",
      "Score: 0.8543727620820537\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.8544  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1093  \u001b[0m | \u001b[0m 0.002221\u001b[0m | \u001b[0m 199.9   \u001b[0m | \u001b[0m 13.74   \u001b[0m | \u001b[0m 30.88   \u001b[0m | \u001b[0m 8.827   \u001b[0m | \u001b[0m 0.7277  \u001b[0m | \u001b[0m 0.007392\u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38df87467a0f48c89eedcb181097dd98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.88064\tvalid_1's auc: 0.841398\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.881808\tvalid_1's auc: 0.838889\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.878746\tvalid_1's auc: 0.837511\n",
      "\n",
      "Fold: 0 \t Score: 0.8405211990425944\n",
      "Fold: 1 \t Score: 0.842845383757177\n",
      "Fold: 2 \t Score: 0.8395635567592012\n",
      "Score: 0.8469181235902821\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.8469  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1765  \u001b[0m | \u001b[0m 0.009601\u001b[0m | \u001b[0m 149.1   \u001b[0m | \u001b[0m 6.918   \u001b[0m | \u001b[0m 39.69   \u001b[0m | \u001b[0m 6.297   \u001b[0m | \u001b[0m 0.5643  \u001b[0m | \u001b[0m 0.1238  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddefe710d6634979b8cb61f1d118a907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.89599\tvalid_1's auc: 0.835803\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.897563\tvalid_1's auc: 0.840315\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.898963\tvalid_1's auc: 0.838666\n",
      "\n",
      "Fold: 0 \t Score: 0.8375142903793111\n",
      "Fold: 1 \t Score: 0.8405598340458352\n",
      "Fold: 2 \t Score: 0.8396732276851702\n",
      "Score: 0.8490578759622779\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.8491  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.02127 \u001b[0m | \u001b[0m 0.001504\u001b[0m | \u001b[0m 199.0   \u001b[0m | \u001b[0m 11.99   \u001b[0m | \u001b[0m 30.26   \u001b[0m | \u001b[0m 6.159   \u001b[0m | \u001b[0m 0.9291  \u001b[0m | \u001b[0m 0.5209  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47535e607234978ac5f19ff212b3d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.886067\tvalid_1's auc: 0.84544\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.885932\tvalid_1's auc: 0.844316\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.886284\tvalid_1's auc: 0.845266\n",
      "\n",
      "Fold: 0 \t Score: 0.8455721325606053\n",
      "Fold: 1 \t Score: 0.8470361632808102\n",
      "Fold: 2 \t Score: 0.8447264726409961\n",
      "Score: 0.851411014834665\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.8514  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.1488  \u001b[0m | \u001b[0m 0.005461\u001b[0m | \u001b[0m 187.8   \u001b[0m | \u001b[0m 14.95   \u001b[0m | \u001b[0m 39.67   \u001b[0m | \u001b[0m 9.819   \u001b[0m | \u001b[0m 0.7908  \u001b[0m | \u001b[0m 0.9187  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d01fe81f1484508ad08dcdc59ec7c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.902696\tvalid_1's auc: 0.818238\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.90374\tvalid_1's auc: 0.816101\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.905997\tvalid_1's auc: 0.812185\n",
      "\n",
      "Fold: 0 \t Score: 0.8114718847819495\n",
      "Fold: 1 \t Score: 0.8108694425072367\n",
      "Fold: 2 \t Score: 0.8114898460134405\n",
      "Score: 0.8268492143263106\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.8268  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.01368 \u001b[0m | \u001b[0m 0.003141\u001b[0m | \u001b[0m 153.0   \u001b[0m | \u001b[0m 14.84   \u001b[0m | \u001b[0m 39.95   \u001b[0m | \u001b[0m 9.127   \u001b[0m | \u001b[0m 0.3599  \u001b[0m | \u001b[0m 0.2544  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714b161843264334a47f3ef1712f978a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.878615\tvalid_1's auc: 0.804837\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.880074\tvalid_1's auc: 0.802163\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.880506\tvalid_1's auc: 0.800533\n",
      "\n",
      "Fold: 0 \t Score: 0.7988859359213284\n",
      "Fold: 1 \t Score: 0.7970483496568546\n",
      "Fold: 2 \t Score: 0.7977825098952822\n",
      "Score: 0.8129069137559245\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.8129  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.01086 \u001b[0m | \u001b[0m 0.003537\u001b[0m | \u001b[0m 119.2   \u001b[0m | \u001b[0m 14.59   \u001b[0m | \u001b[0m 28.09   \u001b[0m | \u001b[0m 6.253   \u001b[0m | \u001b[0m 0.6914  \u001b[0m | \u001b[0m 0.2054  \u001b[0m |\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0501f47b045f4ecc9062a148d96e9750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.88168\tvalid_1's auc: 0.842851\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.882175\tvalid_1's auc: 0.840508\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[95]\ttraining's auc: 0.879384\tvalid_1's auc: 0.838719\n",
      "\n",
      "Fold: 0 \t Score: 0.8427068878419873\n",
      "Fold: 1 \t Score: 0.8444314787890467\n",
      "Fold: 2 \t Score: 0.8402730797898614\n",
      "Score: 0.8485136411304207\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.8485  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.174   \u001b[0m | \u001b[0m 0.009252\u001b[0m | \u001b[0m 84.77   \u001b[0m | \u001b[0m 14.83   \u001b[0m | \u001b[0m 39.44   \u001b[0m | \u001b[0m 6.128   \u001b[0m | \u001b[0m 0.7806  \u001b[0m | \u001b[0m 0.9664  \u001b[0m |\n",
      "=====================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=5, random_seed=6, n_estimators=10000, output_process=False):\n",
    "    # prepare data\n",
    "    Xtr, Xval, ytr, yval  = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "    # parameters\n",
    "    def lgb_eval(num_leaves, feature_fraction, bagging_fraction, learning_rate, num_threads, min_data_in_leaf, min_sum_hessian_in_leaf, reg_alpha, reg_lambda):\n",
    "        # fixed parameters\n",
    "        params = {'application':'binary',\n",
    "                  'num_iterations': n_estimators,\n",
    "                  'learning_rate':learning_rate,\n",
    "                  'early_stopping_round':100,\n",
    "                  'metric':'auc',\n",
    "                  'max_depth':-1,\n",
    "                  'bagging_freq':7,\n",
    "                  'verbosity':-1}\n",
    "        # variables\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['learning_rate'] = learning_rate\n",
    "        params['num_threads'] = int(num_threads)\n",
    "        params['min_data_in_leaf'] = int(min_data_in_leaf)\n",
    "        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n",
    "        params['reg_alpha'] = max(min(reg_alpha, 1), 0)\n",
    "        params['reg_lambda'] = max(min(reg_lambda, 1), 0)\n",
    "        \n",
    "        ms = lgb_trainer_no_aug(Xtr, ytr, params, n_folds)\n",
    "        scorre, q, w = test_f(Xval, yval, ms)\n",
    "#         cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        \n",
    "        return scorre\n",
    "    # range of variables\n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (5, 40),\n",
    "                                            'feature_fraction': (0.01, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 0.1),\n",
    "                                            'learning_rate': (0.001, 0.01),\n",
    "                                            'num_threads': (6, 10),\n",
    "                                            'min_data_in_leaf': (60, 200),\n",
    "                                            'min_sum_hessian_in_leaf': (5.0 , 15.0),\n",
    "                                            'reg_alpha': (0.0 , 1.0),\n",
    "                                            'reg_lambda': (0.0 , 1.0),\n",
    "                                           },\n",
    "                                             random_state=42)\n",
    "    # optimize!\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    # output optimization process\n",
    "    if output_process==True: lgbBO.points_to_csv(\"bayes_opt_result.csv\")\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbBO.res\n",
    "\n",
    "opt_params = bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=35, n_folds=3, random_seed=6, n_estimators=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.8620098138074975,\n",
       " 'params': {'bagging_fraction': 0.8,\n",
       "  'feature_fraction': 0.039575020369471824,\n",
       "  'learning_rate': 0.007665078680394379,\n",
       "  'min_data_in_leaf': 98.92002156410791,\n",
       "  'min_sum_hessian_in_leaf': 14.910533683368534,\n",
       "  'num_leaves': 37.894176676473215,\n",
       "  'num_threads': 6.37590307317559,\n",
       "  'reg_alpha': 0.6718099633747782,\n",
       "  'reg_lambda': 0.07763407837596625}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params[27]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Add #unique values as features (its not good, fuck it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def augment_uniques_no_count(data):\n",
    "    for feature in data.columns:\n",
    "        if feature in ['ID_code', 'target']:\n",
    "            continue\n",
    "        a = np.unique(data[feature])\n",
    "        data[f'count_{feature}'] = np.full(data.shape[0], len(a))\n",
    "    return data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "traindf = augment_uniques_no_count(train)\n",
    "y = traindf.target\n",
    "traindf = traindf.drop(['target', 'ID_code'], axis=1)\n",
    "Xtr, Xval, ytr, yval  = train_test_split(traindf, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>count_var_190</th>\n",
       "      <th>count_var_191</th>\n",
       "      <th>count_var_192</th>\n",
       "      <th>count_var_193</th>\n",
       "      <th>count_var_194</th>\n",
       "      <th>count_var_195</th>\n",
       "      <th>count_var_196</th>\n",
       "      <th>count_var_197</th>\n",
       "      <th>count_var_198</th>\n",
       "      <th>count_var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>114959</td>\n",
       "      <td>94266</td>\n",
       "      <td>59065</td>\n",
       "      <td>110557</td>\n",
       "      <td>97069</td>\n",
       "      <td>57870</td>\n",
       "      <td>125560</td>\n",
       "      <td>40537</td>\n",
       "      <td>94153</td>\n",
       "      <td>149430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>114959</td>\n",
       "      <td>94266</td>\n",
       "      <td>59065</td>\n",
       "      <td>110557</td>\n",
       "      <td>97069</td>\n",
       "      <td>57870</td>\n",
       "      <td>125560</td>\n",
       "      <td>40537</td>\n",
       "      <td>94153</td>\n",
       "      <td>149430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>114959</td>\n",
       "      <td>94266</td>\n",
       "      <td>59065</td>\n",
       "      <td>110557</td>\n",
       "      <td>97069</td>\n",
       "      <td>57870</td>\n",
       "      <td>125560</td>\n",
       "      <td>40537</td>\n",
       "      <td>94153</td>\n",
       "      <td>149430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>114959</td>\n",
       "      <td>94266</td>\n",
       "      <td>59065</td>\n",
       "      <td>110557</td>\n",
       "      <td>97069</td>\n",
       "      <td>57870</td>\n",
       "      <td>125560</td>\n",
       "      <td>40537</td>\n",
       "      <td>94153</td>\n",
       "      <td>149430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>114959</td>\n",
       "      <td>94266</td>\n",
       "      <td>59065</td>\n",
       "      <td>110557</td>\n",
       "      <td>97069</td>\n",
       "      <td>57870</td>\n",
       "      <td>125560</td>\n",
       "      <td>40537</td>\n",
       "      <td>94153</td>\n",
       "      <td>149430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9      ...        count_var_190  count_var_191  count_var_192  \\\n",
       "0  5.7470      ...               114959          94266          59065   \n",
       "1  8.0851      ...               114959          94266          59065   \n",
       "2  5.9525      ...               114959          94266          59065   \n",
       "3  8.2450      ...               114959          94266          59065   \n",
       "4  7.6784      ...               114959          94266          59065   \n",
       "\n",
       "   count_var_193  count_var_194  count_var_195  count_var_196  count_var_197  \\\n",
       "0         110557          97069          57870         125560          40537   \n",
       "1         110557          97069          57870         125560          40537   \n",
       "2         110557          97069          57870         125560          40537   \n",
       "3         110557          97069          57870         125560          40537   \n",
       "4         110557          97069          57870         125560          40537   \n",
       "\n",
       "   count_var_198  count_var_199  \n",
       "0          94153         149430  \n",
       "1          94153         149430  \n",
       "2          94153         149430  \n",
       "3          94153         149430  \n",
       "4          94153         149430  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062e02e96d5840a595b0fe72dd307d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.905608\tvalid_1's auc: 0.877137\n",
      "[10000]\ttraining's auc: 0.912866\tvalid_1's auc: 0.882447\n",
      "[15000]\ttraining's auc: 0.91866\tvalid_1's auc: 0.886165\n",
      "[20000]\ttraining's auc: 0.923428\tvalid_1's auc: 0.888896\n",
      "[25000]\ttraining's auc: 0.9276\tvalid_1's auc: 0.890983\n",
      "[30000]\ttraining's auc: 0.93129\tvalid_1's auc: 0.892571\n",
      "[35000]\ttraining's auc: 0.9346\tvalid_1's auc: 0.893747\n",
      "[40000]\ttraining's auc: 0.937573\tvalid_1's auc: 0.894667\n",
      "[45000]\ttraining's auc: 0.940304\tvalid_1's auc: 0.89531\n",
      "[50000]\ttraining's auc: 0.942856\tvalid_1's auc: 0.895718\n",
      "[55000]\ttraining's auc: 0.945253\tvalid_1's auc: 0.89606\n",
      "[60000]\ttraining's auc: 0.94749\tvalid_1's auc: 0.896274\n",
      "[65000]\ttraining's auc: 0.949614\tvalid_1's auc: 0.896385\n",
      "[70000]\ttraining's auc: 0.951646\tvalid_1's auc: 0.896463\n",
      "[75000]\ttraining's auc: 0.953596\tvalid_1's auc: 0.8965\n",
      "Early stopping, best iteration is:\n",
      "[74139]\ttraining's auc: 0.953271\tvalid_1's auc: 0.89651\n",
      "Training until validation scores don't improve for 4000 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-e2cd42d44d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrank_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_trainer_no_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-b3fbc410fdf3>\u001b[0m in \u001b[0;36mlgb_trainer_no_aug\u001b[0;34m(X, y, params, n_folds)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mtrn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mmodel_lgb\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks_after_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_valid\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   1975\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m         \"\"\"\n\u001b[0;32m-> 1977\u001b[0;31m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0m\u001b[1;32m   1978\u001b[0m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         \"\"\"\n\u001b[1;32m   1977\u001b[0m         return [item for i in range_(1, self.__num_dataset)\n\u001b[0;32m-> 1978\u001b[0;31m                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]\n\u001b[0m\u001b[1;32m   1979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1980\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2362\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2363\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2364\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   2365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rank_models = lgb_trainer_no_aug(Xtr, ytr, param, n_folds = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

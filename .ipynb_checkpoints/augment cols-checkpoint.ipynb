{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "import gc\n",
    "from helpers import save_model, lgb_trainer, lgb_trainer_no_aug, test\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(dataset):\n",
    "    return pd.read_csv(dataset)\n",
    "with multiprocessing.Pool() as pool:\n",
    "    otrain_df, otest_df = pool.map(load_dataframe, ['data/train.csv', 'data/test.csv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(models, filename):\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(models, handle)\n",
    "        \n",
    "def disarrange(a, axis=-1):\n",
    "    \"\"\"\n",
    "    Shuffle `a` in-place along the given axis.\n",
    "\n",
    "    Apply numpy.random.shuffle to the given axis of `a`.\n",
    "    Each one-dimensional slice is shuffled independently.\n",
    "    \"\"\"\n",
    "    b = a.swapaxes(axis, -1)\n",
    "    # Shuffle `b` in-place along the last axis.  `b` is a view of `a`,\n",
    "    # so `a` is shuffled in place, too.\n",
    "    shp = b.shape[:-1]\n",
    "    for ndx in np.ndindex(shp):\n",
    "        np.random.shuffle(b[ndx])\n",
    "    return\n",
    "\n",
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        disarrange(x1,axis=0)\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        disarrange(x1,axis=0)\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y\n",
    "\n",
    "def lgb_trainer(X, y, params, n_folds):\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    models = []\n",
    "    for train_idx, test_idx in skf.split(X.values, y.values):\n",
    "            gc.collect()\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_tr, y_tr = augment(X_train.values, y_train.values)\n",
    "            X_tr = pd.DataFrame(X_tr)\n",
    "            trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "            test_data = lgb.Dataset(X.values[test_idx], label=y.values[test_idx])\n",
    "            model_lgb     = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, test_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "            models.append(model_lgb)\n",
    "            auc = roc_auc_score(y.values[test_idx], model_lgb.predict(X.values[test_idx]))\n",
    "    return models\n",
    "\n",
    "def lgb_trainer_no_aug(X, y, params, n_folds):\n",
    "    skf = StratifiedKFold(n_splits=n_folds)\n",
    "    models = []\n",
    "    for train_idx, test_idx in skf.split(X.values, y.values):\n",
    "            gc.collect()\n",
    "            X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "            X_tr, y_tr = X_train.values, y_train.values\n",
    "            X_tr = pd.DataFrame(X_tr)\n",
    "            trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "            test_data = lgb.Dataset(X.values[test_idx], label=y.values[test_idx])\n",
    "            model_lgb     = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, test_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "            models.append(model_lgb)\n",
    "            auc = roc_auc_score(y.values[test_idx], model_lgb.predict(X.values[test_idx]))\n",
    "    return models\n",
    "\n",
    "def test(X, y, models):\n",
    "    preds = pd.DataFrame({})\n",
    "    for i, model in enumerate(models):\n",
    "        preds[str(i)] = model.predict(X)\n",
    "        print(f\"Fold: {i} \\t Score: {roc_auc_score(y, preds[str(i)].values)}\")\n",
    "    averaged_preds = preds.mean(axis=1)\n",
    "    print(f\"Score: {roc_auc_score(y, averaged_preds)}\")\n",
    "    return averaged_preds, preds\n",
    "\n",
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Augment #1 - Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timetraveller/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "whole = train_df.append(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def augment_squares(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_square'\n",
    "        df[key] = np.square(df[column])\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "whole = augment_squares(whole)\n",
    "train_df, test_df = whole[:200000], whole[200000:]\n",
    "y_train = train_df.target\n",
    "train_df = train_df.drop(['target', 'ID_code'], axis=1)\n",
    "Xtr, Xval, ytr, yval  = train_test_split(train_df, y_train, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.930218\tvalid_1's auc: 0.900855\n",
      "[10000]\ttraining's auc: 0.950958\tvalid_1's auc: 0.902792\n",
      "Early stopping, best iteration is:\n",
      "[10371]\ttraining's auc: 0.952166\tvalid_1's auc: 0.902857\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.931839\tvalid_1's auc: 0.891377\n",
      "[10000]\ttraining's auc: 0.952127\tvalid_1's auc: 0.893871\n",
      "[15000]\ttraining's auc: 0.967181\tvalid_1's auc: 0.893717\n",
      "Early stopping, best iteration is:\n",
      "[11134]\ttraining's auc: 0.955876\tvalid_1's auc: 0.893933\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.930154\tvalid_1's auc: 0.901229\n",
      "[10000]\ttraining's auc: 0.950674\tvalid_1's auc: 0.903684\n",
      "Early stopping, best iteration is:\n",
      "[10767]\ttraining's auc: 0.953312\tvalid_1's auc: 0.903802\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.93154\tvalid_1's auc: 0.894204\n",
      "[10000]\ttraining's auc: 0.952039\tvalid_1's auc: 0.896585\n",
      "Early stopping, best iteration is:\n",
      "[9261]\ttraining's auc: 0.949413\tvalid_1's auc: 0.896642\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.931107\tvalid_1's auc: 0.898272\n",
      "[10000]\ttraining's auc: 0.951509\tvalid_1's auc: 0.900095\n",
      "Early stopping, best iteration is:\n",
      "[8325]\ttraining's auc: 0.945588\tvalid_1's auc: 0.900184\n"
     ]
    }
   ],
   "source": [
    "rank_models = lgb_trainer_no_aug(Xtr, ytr, param, n_folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 \t Score: 0.9011898326312805\n",
      "Fold: 1 \t Score: 0.9018027909059605\n",
      "Fold: 2 \t Score: 0.9008703628374002\n",
      "Fold: 3 \t Score: 0.8995685094888662\n",
      "Fold: 4 \t Score: 0.8996896069395307\n",
      "Score: 0.9020395219259979\n"
     ]
    }
   ],
   "source": [
    "q, w = test(Xval, yval, rank_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Augment #2 - (x-mean)^^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def augment_squares_prime(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_square'\n",
    "        df[key] = np.square(df[column] - df[column].mean())\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timetraveller/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "whole = train_df.append(test_df)\n",
    "whole = augment_squares_prime(whole)\n",
    "train_df, test_df = whole[:200000], whole[200000:]\n",
    "y_train = train_df.target\n",
    "train_df = train_df.drop(['target', 'ID_code'], axis=1)\n",
    "Xtr, Xval, ytr, yval  = train_test_split(train_df, y_train, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.930282\tvalid_1's auc: 0.895956\n",
      "[10000]\ttraining's auc: 0.952013\tvalid_1's auc: 0.900068\n",
      "[15000]\ttraining's auc: 0.967219\tvalid_1's auc: 0.900571\n",
      "Early stopping, best iteration is:\n",
      "[14174]\ttraining's auc: 0.965024\tvalid_1's auc: 0.90065\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.93053\tvalid_1's auc: 0.895697\n",
      "[10000]\ttraining's auc: 0.952317\tvalid_1's auc: 0.899372\n",
      "[15000]\ttraining's auc: 0.967456\tvalid_1's auc: 0.899599\n",
      "Early stopping, best iteration is:\n",
      "[15378]\ttraining's auc: 0.968447\tvalid_1's auc: 0.899663\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.931103\tvalid_1's auc: 0.892626\n",
      "[10000]\ttraining's auc: 0.952853\tvalid_1's auc: 0.89593\n",
      "[15000]\ttraining's auc: 0.96773\tvalid_1's auc: 0.895715\n",
      "Early stopping, best iteration is:\n",
      "[11402]\ttraining's auc: 0.957474\tvalid_1's auc: 0.896116\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.930687\tvalid_1's auc: 0.895183\n",
      "[10000]\ttraining's auc: 0.952137\tvalid_1's auc: 0.898845\n",
      "[15000]\ttraining's auc: 0.967271\tvalid_1's auc: 0.899058\n",
      "Early stopping, best iteration is:\n",
      "[12530]\ttraining's auc: 0.960334\tvalid_1's auc: 0.89933\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.930971\tvalid_1's auc: 0.894435\n",
      "[10000]\ttraining's auc: 0.952373\tvalid_1's auc: 0.897909\n",
      "[15000]\ttraining's auc: 0.967417\tvalid_1's auc: 0.897977\n",
      "Early stopping, best iteration is:\n",
      "[11155]\ttraining's auc: 0.956212\tvalid_1's auc: 0.89819\n"
     ]
    }
   ],
   "source": [
    "rank_models = lgb_trainer_no_aug(Xtr, ytr, param, n_folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0 \t Score: 0.9011898326312805\n",
      "Fold: 1 \t Score: 0.9018027909059605\n",
      "Fold: 2 \t Score: 0.9008703628374002\n",
      "Fold: 3 \t Score: 0.8995685094888662\n",
      "Fold: 4 \t Score: 0.8996896069395307\n",
      "Score: 0.9020395219259979\n"
     ]
    }
   ],
   "source": [
    "q, w = test(Xval, yval, rank_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def augment_exponent(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_square'\n",
    "        df[key] = np.exp(df[column] - df[column].mean())\n",
    "    return df   \n",
    "\n",
    "def augment_exponent_prime(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_square'\n",
    "        df[key] = np.exp(df[column])\n",
    "    return df \n",
    "\n",
    "def augment_squares_prime(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_square'\n",
    "        df[key] = np.square(df[column] - df[column].mean())\n",
    "    return df   \n",
    "\n",
    "def augment_squares(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_square'\n",
    "        df[key] = np.square(df[column])\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timetraveller/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "whole = otrain_df.append(otest_df)\n",
    "whole = augment_exponent(whole)\n",
    "train_df, test_df = whole[:200000], whole[200000:]\n",
    "y_train = train_df.target\n",
    "train_df = train_df.drop(['target', 'ID_code'], axis=1)\n",
    "Xtr, Xval, ytr, yval  = train_test_split(train_df, y_train, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.931132\tvalid_1's auc: 0.89762\n",
      "[10000]\ttraining's auc: 0.951039\tvalid_1's auc: 0.899225\n",
      "Early stopping, best iteration is:\n",
      "[9834]\ttraining's auc: 0.950496\tvalid_1's auc: 0.89929\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.931052\tvalid_1's auc: 0.895564\n",
      "[10000]\ttraining's auc: 0.95098\tvalid_1's auc: 0.897643\n",
      "Early stopping, best iteration is:\n",
      "[9849]\ttraining's auc: 0.950481\tvalid_1's auc: 0.897668\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.929996\tvalid_1's auc: 0.902342\n",
      "[10000]\ttraining's auc: 0.94997\tvalid_1's auc: 0.904284\n",
      "Early stopping, best iteration is:\n",
      "[10374]\ttraining's auc: 0.951237\tvalid_1's auc: 0.90432\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.930996\tvalid_1's auc: 0.897699\n",
      "[10000]\ttraining's auc: 0.950765\tvalid_1's auc: 0.899544\n",
      "Early stopping, best iteration is:\n",
      "[10434]\ttraining's auc: 0.952275\tvalid_1's auc: 0.899608\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.931933\tvalid_1's auc: 0.894221\n",
      "[10000]\ttraining's auc: 0.951695\tvalid_1's auc: 0.895987\n",
      "Early stopping, best iteration is:\n",
      "[9526]\ttraining's auc: 0.950098\tvalid_1's auc: 0.896051\n",
      "Fold: 0 \t Score: 0.9039380632004328\n",
      "Fold: 1 \t Score: 0.9052425814044828\n",
      "Fold: 2 \t Score: 0.9060473210124617\n",
      "Fold: 3 \t Score: 0.9051907492031916\n",
      "Fold: 4 \t Score: 0.9066384762047747\n",
      "Score: 0.9065855269301797\n"
     ]
    }
   ],
   "source": [
    "rank_models = lgb_trainer_no_aug(Xtr, ytr, param, n_folds = 5)\n",
    "q, w = test(Xval, yval, rank_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_exponent(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_exp'\n",
    "        df[key] = np.exp(df[column] - df[column].mean())\n",
    "    return df   \n",
    "\n",
    "def augment_exponent_prime(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_expp'\n",
    "        df[key] = np.exp(df[column])\n",
    "    return df \n",
    "\n",
    "def augment_squares_prime(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_squarep'\n",
    "        df[key] = np.square(df[column] - df[column].mean())\n",
    "    return df   \n",
    "\n",
    "def augment_squares(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_square'\n",
    "        df[key] = np.square(df[column])\n",
    "    return df   \n",
    "\n",
    "def augment_log_prime(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_logp'\n",
    "        df[key] = np.log(df[column] - df[column].mean())\n",
    "    return df   \n",
    "\n",
    "def augment_log(df):\n",
    "    for column in df.columns:\n",
    "        if column in ['ID_code', 'target']:\n",
    "            continue\n",
    "        key = column + '_log'\n",
    "        df[key] = np.log(df[column])\n",
    "    return df   \n",
    "\n",
    "def augment_row_wise(df):\n",
    "    cols = [col for col in df.columns]\n",
    "    df['average'] = df[cols].mean(axis=1)\n",
    "    df['std'] = df[cols].std(axis=1)\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataframe(dataset):\n",
    "    return pd.read_csv(dataset)\n",
    "with multiprocessing.Pool() as pool:\n",
    "    otrain_df, otest_df = pool.map(load_dataframe, ['data/train.csv', 'data/test.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all(otrain_df, otest_df, augmentations, param, n_folds):\n",
    "    all_models = []\n",
    "    for augmentation in augmentations:\n",
    "        if augmentation == 'Normal':\n",
    "            print(f\"Doing augmentation: {augmentation}\")\n",
    "            whole = otrain_df.append(otest_df)\n",
    "        else:    \n",
    "            print(f\"Doing augmentation: {augmentation.__name__}\")\n",
    "            whole = augmentation(otrain_df.append(otest_df))\n",
    "        train_df, test_df = whole[:200000], whole[200000:]\n",
    "        y_train = train_df.target\n",
    "        train_df = train_df.drop(['target', 'ID_code'], axis=1)\n",
    "        models = lgb_trainer_no_aug(train_df, y_train, param, n_folds = n_folds)\n",
    "        models2 = lgb_trainer(train_df, y_train, param, n_folds = n_folds)\n",
    "        all_models += models\n",
    "        all_models += models2\n",
    "    return all_models    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = [augment_row_wise, 'Normal', augment_log, augment_log_prime, augment_exponent, \n",
    "                                         augment_exponent_prime, augment_squares, augment_squares_prime\n",
    "                                        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing augmentation: <function augment_row_wise at 0x7f81841c9598>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/timetraveller/miniconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.933098\tvalid_1's auc: 0.89652\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-3019100b3c7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0motrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-41a081c5addd>\u001b[0m in \u001b[0;36mapply_all\u001b[0;34m(otrain_df, otest_df, augmentations, param, n_folds)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ID_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_trainer_no_aug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmodels2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mall_models\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-208f88668509>\u001b[0m in \u001b[0;36mlgb_trainer_no_aug\u001b[0;34m(X, y, params, n_folds)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mtrn_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mmodel_lgb\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_lgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid_sets\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m                 \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36meval_train\u001b[0;34m(self, feval)\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0mList\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mevaluation\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m         \"\"\"\n\u001b[0;32m-> 1958\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__inner_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__train_data_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__inner_eval\u001b[0;34m(self, data_name, data_idx, feval)\u001b[0m\n\u001b[1;32m   2362\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2363\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_out_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2364\u001b[0;31m                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m   2365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtmp_out_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_inner_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length of eval results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_models = apply_all(otrain_df, otest_df, augmentations, param, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

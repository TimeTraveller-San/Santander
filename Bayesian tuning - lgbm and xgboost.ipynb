{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM parameter tuning using Baysian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skopt import gp_minimize\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 'data/train.csv'\n",
    "TEST = 'data/test.csv'\n",
    "SAMPLE = 'data/sample_submission.csv'\n",
    "train = pd.read_csv(TRAIN)\n",
    "test = pd.read_csv(TEST)\n",
    "X = train.drop(['ID_code', 'target'], axis=1)\n",
    "y = train.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baysian_space  = [\n",
    "          Integer(5, 20, name='num_leaves'),\n",
    "          Integer(50, 200, name='min_child_samples'),\n",
    "          Integer(20, 50,  name='min_data_in_leaf'),\n",
    "          Integer(1, 5, name='bagging_freq'),\n",
    "          Real(0.6, 0.9, name='subsample'),\n",
    "          Real(0.01, 0.1, name='feature_fraction'),\n",
    "          Real(0.001, 0.01, name='learning_rate'),\n",
    "          Real(0.1, 0.5, name='bagging_fraction'),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "val_data = lgb.Dataset(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_optim(values):\n",
    "    params = {'num_leaves': values[0], \n",
    "          'min_child_samples': values[1], \n",
    "          'min_data_in_leaf': values[2], \n",
    "          'bagging_freq': values[3],\n",
    "            'subsample': values[4],\n",
    "            'feature_fraction': values[5],\n",
    "             'learning_rate':values[6],\n",
    "             'bagging_fraction': values[7],\n",
    "             'boosting_type': 'gbdt',\n",
    "             'objective': 'binary',\n",
    "              'max_depth':-1,\n",
    "              'metric':'auc',\n",
    "              'boost_from_average':'false',\n",
    "               'verbosity': -1,\n",
    "              'objective': 'binary',\n",
    "              'tree_learner': 'serial',\n",
    "               'gpu_platform_id': -1,\n",
    "             }\n",
    "    print('\\nNext set of params.....',params)\n",
    "    trn_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_test, label=y_test)\n",
    "    model_lgb     = lgb.train(params, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "    auc = -roc_auc_score(y_train, model_lgb.predict(X_train))\n",
    "    return  auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gp = gp_minimize(lgb_optim, baysian_space, n_calls=20,\n",
    "                     random_state=0,n_random_starts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# RandomForest parameter tuning using Baysian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rf_baysian_space  = [\n",
    "          Integer(15, 200, name='min_samples_leaf'),\n",
    "          Integer(100, 250, name='n_estimators'),\n",
    "          Real(0.1, 0.7, name='max_features'),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rf_optim(values):\n",
    "    params = {'min_samples_leaf': values[0], \n",
    "          'n_estimators': values[1], \n",
    "          'max_features': values[2], \n",
    "           'n_jobs' : -1,\n",
    "           'random_state' : 42,\n",
    "             }\n",
    "    print('\\nNext set of params.....',params)\n",
    "    rf = RandomForestClassifier(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    auc = -roc_auc_score(y_train, rf.predict(X_train))\n",
    "    return  auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res_gp = gp_minimize(rf_optim, rf_baysian_space, n_calls=10,\n",
    "                     random_state=0,n_random_starts=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_lgb_optim(values):\n",
    "    params = {'num_leaves': values[0], \n",
    "          'min_child_samples': values[1], \n",
    "          'min_data_in_leaf': values[2], \n",
    "          'bagging_freq': values[3],\n",
    "            'subsample': values[4],\n",
    "            'feature_fraction': values[5],\n",
    "             'learning_rate':values[6],\n",
    "             'bagging_fraction': values[7],\n",
    "             'boosting_type': 'gbdt',\n",
    "             'objective': 'binary',\n",
    "              'max_depth':-1,\n",
    "              'metric':'auc',\n",
    "              'boost_from_average':'false',\n",
    "               'verbosity': -1,\n",
    "              'objective': 'binary',\n",
    "              'tree_learner': 'serial',\n",
    "               'gpu_platform_id': -1,\n",
    "             }\n",
    "    print('\\nNext set of params.....',params)\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        trn_data = lbd.Dataset(X[train_idx], label=y[train_idx])\n",
    "        test_data = lbd.Dataset(X[test_idx], label=y[test_idx])\n",
    "        model_lgb     = lgb.train(params, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "        auc = roc_auc_score(y[test_idx], model_lgb.predict(X[test_idx]))\n",
    "        return -auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gp = gp_minimize(lgb_optim, baysian_space, n_calls=10,\n",
    "                     random_state=0, n_random_starts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
